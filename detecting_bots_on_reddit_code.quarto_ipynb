{
  "cells": [
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: false\n",
        "import pandas as pd\n",
        "\n",
        "pd.set_option('display.max_columns', 4)  # Limit to 4 columns displayed\n",
        "\n",
        "def glimpse(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Similar to R's glimpse()\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    df : pd.DataFrame\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    pd.DataFrame\n",
        "    \"\"\"\n",
        "    print(f\"Rows: {df.shape[0]}\")\n",
        "    print(f\"Columns: {df.shape[1]}\")\n",
        "\n",
        "    sample_size = min(df.shape[0], 5)\n",
        "\n",
        "    return (\n",
        "        df.sample(sample_size)\n",
        "        .T.assign(dtypes=df.dtypes)\n",
        "        .loc[\n",
        "            :, lambda x: sorted(x.columns, key=lambda col: 0 if col == \"dtypes\" else 1)\n",
        "        ]\n",
        "    )"
      ],
      "id": "1c5a8ca4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import base64\n",
        "import os\n",
        "from dotenv import load_dotenv \n",
        "from google import genai\n",
        "from google.genai import types\n",
        "\n",
        "load_dotenv()\n",
        "\n",
        "# set up LLM parameters\n",
        "def generate(prompt):\n",
        "    client = genai.Client(\n",
        "        api_key=os.getenv(\"GEMINI_API_KEY\"),\n",
        "    )\n",
        "\n",
        "    model = \"gemini-2.0-flash\" # fastest model (used as default on the Gemini web app)\n",
        "    contents = [\n",
        "        types.Content(\n",
        "            role=\"user\",\n",
        "            parts=[\n",
        "                types.Part.from_text(text=prompt),\n",
        "            ],\n",
        "        ),\n",
        "    ]\n",
        "    generate_content_config = types.GenerateContentConfig(\n",
        "        temperature=0, # controls randomness. 0 = most deterministic (always selects highest probability token)\n",
        "        top_p=0, # nucleus sampling: limits token selection to the most probable. 0 = most deterministic (used when temperature > 0)\n",
        "        top_k=1, # restricts to top 'k' tokens. 1 = most deterministic (used when temperature > 0)\n",
        "        max_output_tokens=8192,\n",
        "        response_mime_type=\"text/plain\",\n",
        "    )\n",
        "\n",
        "    complete_response = \"\"\n",
        "    for chunk in client.models.generate_content_stream(\n",
        "        model=model,\n",
        "        contents=contents,\n",
        "        config=generate_content_config,\n",
        "    ):\n",
        "        complete_response += chunk.text\n",
        "\n",
        "    return complete_response"
      ],
      "id": "b9a32da7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import praw\n",
        "import pandas as pd\n",
        "\n",
        "# Replace with your actual credentials\n",
        "reddit = praw.Reddit(\n",
        "    client_id=os.getenv(\"PRAW_CLIENT_ID\"),\n",
        "    client_secret=os.getenv(\"PRAW_CLIENT_SECRET\"),\n",
        "    user_agent=os.getenv(\"PRAW_USER_AGENT\"),\n",
        "    username=os.getenv(\"PRAW_USERNAME\"),\n",
        "    password=os.getenv(\"PRAW_PASSWORD\")\n",
        ")\n",
        "\n",
        "# Fetch a large subset of popular subreddits (large limit makes this representative of the largest overall subreddits by subscribers, check: https://gummysearch.com/tools/top-subreddits/)\n",
        "subreddits = list(reddit.subreddits.popular(limit=1000))\n",
        "\n",
        "# Create a DataFrame using list comprehension for better performance\n",
        "subs_df = pd.DataFrame([{\n",
        "    \"Name\": subreddit.display_name,\n",
        "    \"Subscribers\": subreddit.subscribers,\n",
        "    \"Description\": subreddit.public_description,\n",
        "    \"Over 18\": subreddit.over18,\n",
        "    \"Submission Type\": subreddit.submission_type\n",
        "} for subreddit in subreddits]).sort_values(by=\"Subscribers\", ascending=False, ignore_index=True)\n",
        "\n",
        "# Print the top 10\n",
        "subs_df.head(10)"
      ],
      "id": "c9ba2aaa",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import ast\n",
        "\n",
        "response = generate(\"What are some keywords I can use to create a list of subreddits which are likely to be influenced by bots because of their controversial nature? These are keywords that I would look for within a subreddit's name or description. For example: \\\"news\\\", \\\"politics\\\", \\\"discussion\\\", \\\"war\\\", \\\"vaccines\\\", \\\"controversial\\\", \\\"conflict\\\", etc.\\n\\nKeep the answer short, only including 50 keywords and saving them in a python list as follows [\\\"key1\\\",\\\"key2\\\",...]. Send the output as text not as code.\")\n",
        "\n",
        "bot_influence_keywords = ast.literal_eval(response.replace(\"\\n\", \"\"))\n",
        "\n",
        "for i in range(0, len(bot_influence_keywords), 5):\n",
        "    print(*bot_influence_keywords[i:i+5])"
      ],
      "id": "8d311eaa",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Score subreddits based on subscribers and keywords in description\n",
        "def calculate_bot_influence_score(row):\n",
        "    score = 0\n",
        "    \n",
        "    # Large subscriber base increases potential for bot activity\n",
        "    if row['Subscribers'] > 10000000:\n",
        "        score += 5\n",
        "    elif row['Subscribers'] > 5000000:\n",
        "        score += 4\n",
        "    elif row['Subscribers'] > 1000000:\n",
        "        score += 3\n",
        "        \n",
        "    # Check for keywords in description and subreddit name\n",
        "    description = row['Description'].lower()\n",
        "    sub_name = row['Name'].lower()\n",
        "    for keyword in bot_influence_keywords:\n",
        "        if keyword in description:\n",
        "            score += 1\n",
        "        if keyword in sub_name:\n",
        "            score += 1\n",
        "            \n",
        "    return score\n",
        "\n",
        "subs_df['Bot Score'] = subs_df.apply(calculate_bot_influence_score, axis=1)\n",
        "\n",
        "# Get top 50 most vulnerable subreddits\n",
        "top_vulnerable = subs_df.nlargest(50, 'Bot Score')[['Name', 'Subscribers', 'Submission Type', 'Bot Score']].reset_index(drop=True)\n",
        "top_vulnerable.head(10)"
      ],
      "id": "8dd5679a",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| output: false\n",
        "# Filter the DataFrame to include only the desired subreddits\n",
        "subreddits_of_interest = ['worldnews', 'news', 'politics', 'science', 'technology']\n",
        "top_vulnerable_filtered = top_vulnerable[top_vulnerable['Name'].isin(subreddits_of_interest)].reset_index(drop=True)\n",
        "\n",
        "top_vulnerable_filtered"
      ],
      "id": "72fe92df",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| eval: false\n",
        "import time\n",
        "import concurrent.futures\n",
        "\n",
        "# Function to Fetch Posts and Comments\n",
        "def fetch_posts_and_comments(subreddit_name, num_posts=50, num_comments=2000):\n",
        "    \"\"\"\n",
        "    Fetches posts and their comments from a subreddit, including comment levels and parent comment ID.\n",
        "\n",
        "    Args:\n",
        "        subreddit_name: The name of the subreddit.\n",
        "        num_posts: The maximum number of posts to fetch.\n",
        "        num_comments: The maximum number of comments to fetch per post (total, across all levels).\n",
        "\n",
        "    Returns:\n",
        "        A list of dictionaries, where each dictionary represents a post and its comments,\n",
        "        with each comment including its level and parent comment ID.\n",
        "    \"\"\"\n",
        "    subreddit = reddit.subreddit(subreddit_name)\n",
        "    posts_data = []\n",
        "\n",
        "    try:\n",
        "        for post in subreddit.hot(limit=num_posts):  # You can change 'hot' to 'new', 'rising', etc.\n",
        "            post_data = {\n",
        "                \"subreddit\": subreddit_name,\n",
        "                \"post_id\": post.id,\n",
        "                \"post_title\": post.title,\n",
        "                \"post_author\": str(post.author),\n",
        "                \"post_score\": post.score,\n",
        "                \"post_upvote_ratio\": post.upvote_ratio,\n",
        "                \"post_url\": post.url,\n",
        "                \"post_selftext\": post.selftext,\n",
        "                \"post_created_utc\": post.created_utc,\n",
        "                \"comments\": []\n",
        "            }\n",
        "\n",
        "            def fetch_comments_recursive(comments, level=1, comment_count=0, parent_id=None):\n",
        "                comment_data = []\n",
        "                for comment in comments:\n",
        "                    if comment_count >= num_comments:\n",
        "                        break  # Stop fetching comments if the limit is reached\n",
        "\n",
        "                    comment_data.append({\n",
        "                        \"comment_id\": comment.id,\n",
        "                        \"comment_author\": str(comment.author),\n",
        "                        \"comment_body\": comment.body,\n",
        "                        \"comment_score\": comment.score,\n",
        "                        \"comment_created_utc\": comment.created_utc,\n",
        "                        \"comment_level\": level,  # Add the comment level\n",
        "                        \"parent_id\": parent_id  # Add the parent comment ID\n",
        "                    })\n",
        "                    comment_count += 1\n",
        "\n",
        "                    # Fetch replies recursively\n",
        "                    if hasattr(comment, 'replies'):\n",
        "                        comment.replies.replace_more(limit=0)  # Ensure all 'MoreComments' are resolved\n",
        "                        replies_data, comment_count = fetch_comments_recursive(comment.replies, level + 1, comment_count, comment.id)\n",
        "                        comment_data.extend(replies_data)\n",
        "\n",
        "                return comment_data, comment_count\n",
        "\n",
        "            post.comments.replace_more(limit=0)  # Ensure all top-level 'MoreComments' are resolved\n",
        "            comments_data, _ = fetch_comments_recursive(post.comments)\n",
        "            post_data[\"comments\"] = comments_data\n",
        "\n",
        "            posts_data.append(post_data)\n",
        "\n",
        "            # Respect API rate limits\n",
        "            # time.sleep(1)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error fetching data from r/{subreddit_name}: {e}\")\n",
        "\n",
        "    return posts_data\n",
        "\n",
        "# Main Data Collection Loop\n",
        "all_data = []\n",
        "subreddit_names = top_vulnerable_filtered['Name'].tolist()\n",
        "num_cores = os.cpu_count()  # Get the number of CPU cores\n",
        "\n",
        "with concurrent.futures.ThreadPoolExecutor(max_workers=num_cores) as executor:\n",
        "    # Submit tasks to the executor\n",
        "    futures = [executor.submit(fetch_posts_and_comments, subreddit_name, num_posts=50, num_comments=50) for subreddit_name in subreddit_names]\n",
        "\n",
        "    # Wait for all tasks to complete and collect results\n",
        "    for future in concurrent.futures.as_completed(futures):\n",
        "        try:\n",
        "            subreddit_data = future.result()\n",
        "            all_data.extend(subreddit_data)\n",
        "        except Exception as e:\n",
        "            print(f\"Error fetching data: {e}\")\n",
        "\n",
        "# Convert to DataFrame\n",
        "reddit_data_df = pd.DataFrame(all_data)\n",
        "\n",
        "# Convert lists of comments to a separate DataFrame if desired\n",
        "comments_data = []\n",
        "for index, row in reddit_data_df.iterrows():\n",
        "    for comment in row['comments']:\n",
        "        comment['post_id'] = row['post_id'] # add the relationship\n",
        "        comments_data.append(comment)\n",
        "comments_df = pd.DataFrame(comments_data)\n",
        "# Expand the comments into its own columns\n",
        "# reddit_data_df = pd.concat([reddit_data_df.drop(['comments'], axis=1), pd.DataFrame(reddit_data_df['comments'].tolist()).add_prefix('comment_')], axis=1)\n",
        "\n",
        "# Export to CSV\n",
        "reddit_data_df.to_csv(\"reddit_posts_and_comments.csv\", index=False)\n",
        "comments_df.to_csv(\"comments.csv\", index=False)"
      ],
      "id": "fc081f3e",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import pandas as pd\n",
        "\n",
        "reddit_data_df = pd.read_csv(\"workspaces/reddit_posts_and_comments_03-21-1950.csv\")\n",
        "\n",
        "reddit_data_df.head(10)"
      ],
      "id": "1c7550b2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "comments_df = pd.read_csv(\"workspaces/comments_03-21-1950.csv\")\n",
        "comments_df = comments_df.dropna(subset=['comment_author'])  # Drop rows with missing author names (removed posts)\n",
        "\n",
        "comments_df.head(10)"
      ],
      "id": "ddc13cd1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import numpy as np\n",
        "\n",
        "# Merge reddit_data_df with comments_df\n",
        "comments_df = comments_df.merge(reddit_data_df[['post_id', 'post_author', 'subreddit', 'post_created_utc']], on='post_id', how='left')\n",
        "\n",
        "# Convert UTC timestamps to datetime objects and add a new column for the time taken to comment on a post\n",
        "comments_df['comment_created_utc'] = pd.to_datetime(comments_df['comment_created_utc'], unit='s')\n",
        "comments_df['post_created_utc'] = pd.to_datetime(comments_df['post_created_utc'], unit='s')\n",
        "\n",
        "comments_df['post_to_comment_time'] = comments_df['comment_created_utc'] - comments_df['post_created_utc']\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "# Calculate comment length\n",
        "comments_df['comment_length'] = comments_df['comment_body'].str.len()\n",
        "\n",
        "# Calculate the ratio of comment length to post-to-comment time.  Convert the timedelta to seconds.\n",
        "comments_df['comment_speed_from_post'] = comments_df['comment_length'] / comments_df['post_to_comment_time'].dt.total_seconds()\n",
        "# Calculate the time difference between a comment and its parent comment.\n",
        "\n",
        "# First, we need to merge comments_df with itself to get the creation time of the parent comment.\n",
        "comments_df = comments_df.merge(comments_df[['comment_id', 'comment_created_utc']], left_on='parent_id', right_on='comment_id', suffixes=('', '_parent'), how='left')\n",
        "\n",
        "# Calculate the time difference.  If parent_id is NaN, then the time difference will be NaN\n",
        "comments_df['comment_to_parent_time'] = comments_df['comment_created_utc'] - comments_df['comment_created_utc_parent']\n",
        "\n",
        "# Calculate comment speed from parent. Convert the timedelta to seconds.\n",
        "comments_df['comment_speed_from_parent'] = comments_df['comment_length'] / comments_df['comment_to_parent_time'].dt.total_seconds()\n",
        "# Identify comments made by the original poster (OP)\n",
        "comments_df['is_op'] = np.where(comments_df['post_author'] == comments_df['comment_author'], True, False)\n",
        "\n",
        "comments_df.head(10)"
      ],
      "id": "2d789073",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| eval: false\n",
        "import praw\n",
        "import os\n",
        "from datetime import datetime\n",
        "import pandas as pd\n",
        "\n",
        "reddit = praw.Reddit(\n",
        "    client_id=os.getenv(\"PRAW_CLIENT_ID\"),\n",
        "    client_secret=os.getenv(\"PRAW_CLIENT_SECRET\"),\n",
        "    user_agent=os.getenv(\"PRAW_USER_AGENT\"),\n",
        "    username=os.getenv(\"PRAW_USERNAME\"),\n",
        "    password=os.getenv(\"PRAW_PASSWORD\")\n",
        ")\n",
        "\n",
        "unique_users = comments_df['comment_author'].unique().tolist()\n",
        "\n",
        "user_metrics_cache = {}  # Dictionary to store user metrics\n",
        "\n",
        "def get_user_metrics(author_name):\n",
        "    \"\"\"\n",
        "    Fetches account age and karma for a given Reddit username.\n",
        "    Uses a cache to avoid repeated API calls for the same user.\n",
        "\n",
        "    Args:\n",
        "        author_name (str): The Reddit username.\n",
        "\n",
        "    Returns:\n",
        "        tuple: A tuple containing account age in days and karma score.\n",
        "               Returns (None, None) if there's an error.\n",
        "    \"\"\"\n",
        "    if author_name in user_metrics_cache:\n",
        "        return user_metrics_cache[author_name]\n",
        "\n",
        "    try:\n",
        "        user = reddit.redditor(author_name)\n",
        "\n",
        "        # Account Age\n",
        "        account_creation_time = datetime.fromtimestamp(user.created_utc)\n",
        "        age_in_days = (datetime.now() - account_creation_time).days\n",
        "\n",
        "        # Karma\n",
        "        karma = user.comment_karma + user.link_karma\n",
        "\n",
        "        user_metrics_cache[author_name] = (age_in_days, karma)  # Store in cache\n",
        "        return age_in_days, karma\n",
        "\n",
        "    except praw.exceptions.APIException as e:\n",
        "        print(f\"Error fetching metrics for {author_name}: {e}\")\n",
        "        return None, None\n",
        "    except Exception as e:\n",
        "        print(f\"Error fetching metrics for {author_name}: {e}\")\n",
        "        return None, None\n",
        "\n",
        "user_data = {}\n",
        "for i, user in enumerate(unique_users):\n",
        "    age, karma = get_user_metrics(user)\n",
        "    user_data[user] = {'account_age_days': age, 'karma': karma}\n",
        "\n",
        "    if (i + 1) % 1000 == 0:\n",
        "        print(f\"Processed {i + 1}/{len(unique_users)} users\")\n",
        "\n",
        "# Map the user data back to the comments_df\n",
        "comments_df['account_age_days'] = comments_df['comment_author'].map(lambda x: user_data[x]['account_age_days'])\n",
        "comments_df['karma'] = comments_df['comment_author'].map(lambda x: user_data[x]['karma'])\n",
        "\n",
        "# Identify users with missing account age or karma\n",
        "missing_users = comments_df[comments_df['account_age_days'].isnull()]['comment_author'].tolist()\n",
        "\n",
        "print(f\"Number of rows with missing data: {len(missing_users)}\")\n",
        "\n",
        "# Retry fetching metrics for missing users\n",
        "if missing_users:\n",
        "    print(\"Retrying fetching metrics for missing users...\")\n",
        "    for user in missing_users:\n",
        "        age, karma = get_user_metrics(user)\n",
        "        \n",
        "        # Update the user_data dictionary and DataFrame\n",
        "        user_data[user] = {'account_age_days': age, 'karma': karma}\n",
        "        comments_df.loc[comments_df['comment_author'] == user, 'account_age_days'] = age\n",
        "        comments_df.loc[comments_df['comment_author'] == user, 'karma'] = karma\n",
        "        \n",
        "        if age is not None and karma is not None:\n",
        "            print(f\"Fetched data for user: {user} - Age: {age}, Karma: {karma}\")\n",
        "\n",
        "    print(\"Finished retrying fetching metrics for missing users.\")\n",
        "else:\n",
        "    print(\"No users with missing data.\")\n",
        "\n",
        "# Verify that there are no more missing values\n",
        "print(f\"Number of rows with missing data after retry: {comments_df['account_age_days'].isnull().sum()}\")\n",
        "\n",
        "# Drop rows where 'account_age_days' or 'karma' is NaN\n",
        "comments_df = comments_df.dropna(subset=['account_age_days', 'karma'])\n",
        "\n",
        "comments_df.to_csv(\"processed_comments.csv\", index=False)\n",
        "\n",
        "comments_df.head(10)"
      ],
      "id": "b5af8401",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| eval: false\n",
        "import time\n",
        "\n",
        "unique_authors = comments_df['comment_author'].unique()\n",
        "\n",
        "all_comments = []\n",
        "\n",
        "for i, author in enumerate(unique_authors):\n",
        "    retries = 3  # Number of retries\n",
        "    for attempt in range(retries):\n",
        "        try:\n",
        "            user = reddit.redditor(author)\n",
        "            comments = user.comments.new(limit=10)\n",
        "            for comment in comments:\n",
        "                comment_data = {\n",
        "                    'author': author,\n",
        "                    'comment_id': comment.id,\n",
        "                    'body': comment.body,\n",
        "                    'score': comment.score,\n",
        "                    'subreddit': comment.subreddit.display_name,\n",
        "                    'created_utc': comment.created_utc,\n",
        "                    'permalink': comment.permalink\n",
        "                }\n",
        "                all_comments.append(comment_data)\n",
        "            break  # If successful, break out of the retry loop\n",
        "        except Exception as e:\n",
        "            print(f\"Could not retrieve comments for {author} (Attempt {attempt + 1}/{retries}): {e}\")\n",
        "            if attempt < retries - 1:\n",
        "                time.sleep(10)  # Wait for 10 seconds before retrying\n",
        "            else:\n",
        "                print(f\"Failed to retrieve comments for {author} after {retries} attempts.\")\n",
        "    if (i + 1) % 1000 == 0:\n",
        "        print(f\"Processed {i + 1}/{len(unique_authors)} authors\")\n",
        "\n",
        "recent_user_comments = pd.DataFrame(all_comments)\n",
        "\n",
        "recent_user_comments['created_utc'] = pd.to_datetime(recent_user_comments['created_utc'], unit='s')\n",
        "\n",
        "recent_user_comments.to_csv(\"recent_user_comments.csv\", index=False)\n",
        "\n",
        "recent_user_comments.head(10)"
      ],
      "id": "4312b7ab",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import pandas as pd\n",
        "\n",
        "processed_comments = pd.read_csv('workspaces/processed_comments.csv')\n",
        "\n",
        "processed_comments.head(10)"
      ],
      "id": "cfb830f9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "recent_user_comments = pd.read_csv('workspaces/recent_user_comments.csv')\n",
        "\n",
        "recent_user_comments.head(10)"
      ],
      "id": "e9bd2873",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import numpy as np\n",
        "\n",
        "def calculate_comment_similarity(comments):\n",
        "    \"\"\"\n",
        "    Calculates the average cosine similarity between comments for a given user.\n",
        "\n",
        "    Args:\n",
        "        comments (list): A list of comment bodies (strings).\n",
        "\n",
        "    Returns:\n",
        "        float: The average cosine similarity score.\n",
        "    \"\"\"\n",
        "    if len(comments) < 2:\n",
        "        return 0.0  # Return 0 if there are fewer than 2 comments\n",
        "\n",
        "    vectorizer = TfidfVectorizer()\n",
        "    tfidf_matrix = vectorizer.fit_transform(comments)\n",
        "\n",
        "    # Calculate cosine similarity matrix\n",
        "    similarity_matrix = cosine_similarity(tfidf_matrix)\n",
        "\n",
        "    # Sum the upper triangle of the matrix (excluding the diagonal)\n",
        "    sum_of_similarities = np.sum(np.triu(similarity_matrix, k=1))\n",
        "\n",
        "    # Count the number of pairs (upper triangle elements)\n",
        "    num_pairs = len(comments) * (len(comments) - 1) / 2\n",
        "\n",
        "    if num_pairs == 0:\n",
        "        return 0.0\n",
        "\n",
        "    return sum_of_similarities / num_pairs\n",
        "\n",
        "def calculate_median_time_between_comments(timestamps):\n",
        "    \"\"\"\n",
        "    Calculates the median time difference between consecutive comments for a given user.\n",
        "\n",
        "    Args:\n",
        "        timestamps (list): A list of comment creation timestamps (datetime objects).\n",
        "\n",
        "    Returns:\n",
        "        float: The median time difference in seconds.\n",
        "    \"\"\"\n",
        "    if len(timestamps) < 2:\n",
        "        return np.nan  # Not enough comments to calculate median time\n",
        "\n",
        "    # Sort timestamps in ascending order\n",
        "    timestamps = sorted(timestamps)\n",
        "\n",
        "    # Convert timestamps to datetime objects\n",
        "    timestamps = pd.to_datetime(timestamps, unit='s')\n",
        "\n",
        "    # Calculate time differences between consecutive comments\n",
        "    time_diffs = [\n",
        "        (timestamps[i+1] - timestamps[i]).total_seconds()\n",
        "        for i in range(len(timestamps) - 1)\n",
        "    ]\n",
        "\n",
        "    return np.median(time_diffs)\n",
        "\n",
        "# Group comments by author\n",
        "grouped_comments = recent_user_comments.groupby('author')\n",
        "\n",
        "user_features = []\n",
        "\n",
        "for author, group in grouped_comments:\n",
        "    # Extract comment bodies and timestamps for the current author\n",
        "    comment_bodies = group['body'].tolist()\n",
        "    comment_times = group['created_utc'].tolist()\n",
        "\n",
        "    # Calculate comment similarity\n",
        "    content_similarity = calculate_comment_similarity(comment_bodies)\n",
        "\n",
        "    # Calculate median time between comments\n",
        "    median_time_between_comments = calculate_median_time_between_comments(comment_times)\n",
        "    \n",
        "    # Calculate average comment length\n",
        "    avg_comment_length = np.mean([len(comment) for comment in comment_bodies])\n",
        "\n",
        "    user_features.append({\n",
        "        'comment_author': author,\n",
        "        'content_cosine_similarity': content_similarity,\n",
        "        'median_secs_between_comments': median_time_between_comments,\n",
        "        'avg_comment_length_chars': avg_comment_length\n",
        "    })\n",
        "\n",
        "user_features_df = pd.DataFrame(user_features)\n",
        "\n",
        "user_features_df.head(10)"
      ],
      "id": "07b27f25",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "processed_comments = pd.merge(processed_comments, user_features_df, left_on='comment_author', right_on='comment_author', how='left')\n",
        "\n",
        "# Remove rows where any of the merged columns have missing values\n",
        "processed_comments = processed_comments.dropna(subset=['content_cosine_similarity', 'median_secs_between_comments', 'avg_comment_length_chars'])\n",
        "\n",
        "processed_comments.head(10)"
      ],
      "id": "aa0bbc9a",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "ml_features = processed_comments[[\n",
        "    'comment_author', 'comment_body', 'comment_score', 'comment_level', 'subreddit', 'comment_length', 'comment_speed_from_post', 'comment_speed_from_parent', 'is_op', 'account_age_days', 'karma', 'content_cosine_similarity', 'median_secs_between_comments', 'avg_comment_length_chars'\n",
        "]].copy()\n",
        "\n",
        "ml_features.head(10)"
      ],
      "id": "d01d333a",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import numpy as np\n",
        "\n",
        "# Replace infinite values in 'comment_speed_from_post' with a large number\n",
        "ml_features['comment_speed_from_post'] = ml_features['comment_speed_from_post'].replace([float('inf'), float('-inf')], ml_features['comment_speed_from_post'][~np.isinf(ml_features['comment_speed_from_post'])].max() * 10)\n",
        "\n",
        "# Define the quantiles for comment_speed_from_parent\n",
        "quantiles = ml_features['comment_speed_from_parent'].quantile([0.5, 0.95, 0.99])\n",
        "\n",
        "# Create categories for comment_speed_from_parent\n",
        "def categorize_speed(speed):\n",
        "    if pd.isna(speed):\n",
        "        return 'Unsuspicious'\n",
        "    elif speed <= quantiles[0.95]:\n",
        "        return 'Unsuspicious'\n",
        "    elif speed <= quantiles[0.99]:\n",
        "        return 'Suspicious'\n",
        "    else:\n",
        "        return 'Very Suspicious'\n",
        "\n",
        "# Apply the categorization and create a new categorical feature\n",
        "ml_features['comment_speed_from_parent_category'] = ml_features['comment_speed_from_parent'].apply(categorize_speed).astype('category')\n",
        "\n",
        "# Drop the original 'comment_speed_from_parent' column\n",
        "ml_features = ml_features.drop('comment_speed_from_parent', axis=1)\n",
        "\n",
        "# Add a feature for emdash presence\n",
        "ml_features['has_emdash'] = ml_features['comment_body'].str.contains('—').astype(int)\n",
        "\n",
        "ml_features.head(10)"
      ],
      "id": "378ff4a6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "ml_features['very_likely_bot'] = 0  # Initialize the column with 0\n",
        "\n",
        "# Define thresholds for bot-like behavior\n",
        "median_time_threshold = 30  # seconds\n",
        "comment_speed_threshold = ml_features['comment_speed_from_post'].quantile(0.999)  # 999th thousandth quantile\n",
        "\n",
        "# Label as bot if median time between comments is very low\n",
        "ml_features.loc[ml_features['median_secs_between_comments'] <= median_time_threshold, 'very_likely_bot'] = 1\n",
        "\n",
        "# Label as bot if comment speed from post is very high and user is not OP\n",
        "ml_features.loc[(ml_features['comment_speed_from_post'] >= comment_speed_threshold) & (ml_features['is_op'] == 0), 'very_likely_bot'] = 1\n",
        "\n",
        "# Label as bot if emdash is present and other features are suspicious\n",
        "ml_features.loc[\n",
        "    (ml_features['has_emdash'] == 1) &\n",
        "    ((ml_features['comment_speed_from_post'] >= ml_features['comment_speed_from_post'].quantile(0.99)) |\n",
        "     (ml_features['comment_speed_from_parent_category'] == \"Very Suspicious\") |\n",
        "     (ml_features['content_cosine_similarity'] >= ml_features['content_cosine_similarity'].quantile(0.99)) |\n",
        "     (ml_features['median_secs_between_comments'] >= ml_features['median_secs_between_comments'].quantile(0.99))),\n",
        "    'very_likely_bot'\n",
        "] = 1\n",
        "\n",
        "# If a user has been assigned very_likely_bot to one of their comments, assign the tag to all of their comments (ie all rows where comment_author is the very_likely_bot user)\n",
        "bot_authors = ml_features.loc[ml_features['very_likely_bot'] == 1, 'comment_author'].unique()\n",
        "\n",
        "for author in bot_authors:\n",
        "    ml_features.loc[ml_features['comment_author'] == author, 'very_likely_bot'] = 1\n",
        "\n",
        "ml_features.head(10)"
      ],
      "id": "2a4b88e9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "ml_features['possible_bot'] = 0\n",
        "\n",
        "# Define thresholds\n",
        "median_time_threshold = 120  # seconds\n",
        "content_similarity_threshold = ml_features['content_cosine_similarity'].quantile(0.995)\n",
        "account_age_threshold = ml_features['account_age_days'].quantile(0.01)\n",
        "comment_speed_threshold = ml_features['comment_speed_from_post'].quantile(0.99)\n",
        "avg_comment_length_threshold = ml_features['avg_comment_length_chars'].quantile(0.01)\n",
        "\n",
        "# Apply conditions\n",
        "ml_features.loc[\n",
        "    (ml_features['comment_speed_from_parent_category'] == \"Very Suspicious\") |\n",
        "    (ml_features['median_secs_between_comments'] <= median_time_threshold) |\n",
        "    (ml_features['content_cosine_similarity'] >= content_similarity_threshold) |\n",
        "    (ml_features['account_age_days'] <= account_age_threshold) |\n",
        "    (ml_features['comment_speed_from_post'] >= comment_speed_threshold) |\n",
        "    (ml_features['has_emdash'] == 1) |\n",
        "    (ml_features['avg_comment_length_chars'] <= avg_comment_length_threshold) |\n",
        "    (ml_features['very_likely_bot'] == 1),\n",
        "    'possible_bot'\n",
        "] = 1\n",
        "\n",
        "# If a user has been assigned possible_bot to one of their comments, assign the tag to all of their comments (ie all rows where comment_author is the possible_bot user)\n",
        "possible_bot_authors = ml_features.loc[ml_features['possible_bot'] == 1, 'comment_author'].unique()\n",
        "\n",
        "for author in bot_authors:\n",
        "    ml_features.loc[ml_features['comment_author'] == author, 'possible_bot'] = 1\n",
        "\n",
        "ml_features.head(10)"
      ],
      "id": "9a14c24d",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "import seaborn as sns\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Create a new target variable\n",
        "ml_features['bot_category'] = 0  # Default: not a bot\n",
        "ml_features.loc[ml_features['possible_bot'] == 1, 'bot_category'] = 1  # Possible bot\n",
        "ml_features.loc[ml_features['very_likely_bot'] == 1, 'bot_category'] = 2  # Very likely bot\n",
        "\n",
        "# Convert comment_speed_from_parent_category to categorical type\n",
        "ml_features['comment_speed_from_parent_category'] = pd.Categorical(\n",
        "    ml_features['comment_speed_from_parent_category'],\n",
        "    categories=['Unsuspicious', 'Suspicious', 'Very Suspicious'],\n",
        "    ordered=True\n",
        ")\n",
        "\n",
        "# Convert the categorical column to numerical before grouping\n",
        "ml_features['comment_speed_from_parent_category_numerical'] = ml_features['comment_speed_from_parent_category'].cat.codes\n",
        "\n",
        "# Group by user to create a user-level dataset\n",
        "user_level_data = ml_features.groupby('comment_author').agg({\n",
        "    'content_cosine_similarity': 'first',\n",
        "    'median_secs_between_comments': 'first',\n",
        "    'avg_comment_length_chars': 'first',\n",
        "    'comment_speed_from_post': 'median',\n",
        "    'comment_length': 'median',\n",
        "    'account_age_days': 'first',\n",
        "    'karma': 'first',\n",
        "    'has_emdash': 'max',\n",
        "    'comment_speed_from_parent_category_numerical': 'mean',\n",
        "    'bot_category': 'first'\n",
        "}).reset_index()\n",
        "\n",
        "# After grouping, rename the numerical column back to the original name and fill NaN values\n",
        "user_level_data.rename(columns={'comment_speed_from_parent_category_numerical': 'comment_speed_from_parent_category'}, inplace=True)\n",
        "user_level_data['comment_speed_from_parent_category'] = user_level_data['comment_speed_from_parent_category'].fillna(-1)\n",
        "\n",
        "# Prepare features and target\n",
        "X = user_level_data.drop(['comment_author', 'bot_category'], axis=1)\n",
        "y = user_level_data['bot_category']\n",
        "\n",
        "# Split the data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42069666, stratify=y)\n",
        "\n",
        "# Scale the features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Initialize models\n",
        "models = {\n",
        "    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42),\n",
        "    'SVM': SVC(probability=True, random_state=42),\n",
        "    'Neural Network': MLPClassifier(hidden_layer_sizes=(50, 25), max_iter=1000, random_state=42)\n",
        "}\n",
        "\n",
        "# Train and evaluate models\n",
        "results = {}\n",
        "\n",
        "for name, model in models.items():\n",
        "    # Train the model\n",
        "    model.fit(X_train_scaled, y_train)\n",
        "    \n",
        "    # Make predictions\n",
        "    y_pred = model.predict(X_test_scaled)\n",
        "    \n",
        "    # Calculate metrics\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    precision = precision_score(y_test, y_pred, average='weighted')\n",
        "    recall = recall_score(y_test, y_pred, average='weighted')\n",
        "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "    \n",
        "    # Store results\n",
        "    results[name] = {\n",
        "        'Accuracy': accuracy,\n",
        "        'Precision': precision,\n",
        "        'Recall': recall,\n",
        "        'F1 Score': f1,\n",
        "        'Confusion Matrix': confusion_matrix(y_test, y_pred),\n",
        "        'Model': model\n",
        "    }\n",
        "    \n",
        "    print(f\"{name} Results:\")\n",
        "    print(f\"Accuracy: {accuracy:.4f}\")\n",
        "    print(f\"Precision: {precision:.4f}\")\n",
        "    print(f\"Recall: {recall:.4f}\")\n",
        "    print(f\"F1 Score: {f1:.4f}\")\n",
        "    print(\"Confusion Matrix:\")\n",
        "    print(confusion_matrix(y_test, y_pred))\n",
        "    print(\"\\n\")\n",
        "\n",
        "# Plot results\n",
        "metrics = ['Accuracy', 'Precision', 'Recall', 'F1 Score']\n",
        "results_df = pd.DataFrame({\n",
        "    model_name: [results[model_name][metric] for metric in metrics]\n",
        "    for model_name in models.keys()\n",
        "}, index=metrics)\n",
        "\n",
        "# Plot the metrics comparison\n",
        "plt.figure(figsize=(10, 6))\n",
        "results_df.plot(kind='bar')\n",
        "plt.title('Model Performance Comparison')\n",
        "plt.ylabel('Score')\n",
        "plt.xlabel('Metric')\n",
        "plt.xticks(rotation=45)\n",
        "plt.legend(title='Model')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Plot confusion matrices\n",
        "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
        "model_names = list(models.keys())\n",
        "\n",
        "for i, (name, ax) in enumerate(zip(model_names, axes)):\n",
        "    cm = results[name]['Confusion Matrix']\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax)\n",
        "    ax.set_title(f'{name} Confusion Matrix')\n",
        "    ax.set_xlabel('Predicted Labels')\n",
        "    ax.set_ylabel('True Labels')\n",
        "    ax.set_xticklabels(['Not Bot', 'Possible Bot', 'Very Likely Bot'])\n",
        "    ax.set_yticklabels(['Not Bot', 'Possible Bot', 'Very Likely Bot'])\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Feature importance for Random Forest\n",
        "if 'Random Forest' in results:\n",
        "    rf_model = results['Random Forest']['Model']\n",
        "    feature_importance = pd.DataFrame({\n",
        "        'Feature': X.columns,\n",
        "        'Importance': rf_model.feature_importances_\n",
        "    }).sort_values(by='Importance', ascending=False)\n",
        "    \n",
        "    plt.figure(figsize=(10, 6))\n",
        "    sns.barplot(x='Importance', y='Feature', data=feature_importance)\n",
        "    plt.title('Random Forest Feature Importance')\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "id": "e819e080",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from sklearn.decomposition import PCA\n",
        "from sklearn.cluster import KMeans, DBSCAN\n",
        "from sklearn.metrics import silhouette_score\n",
        "\n",
        "# Prepare features\n",
        "X = user_level_data.drop(['comment_author', 'bot_category'], axis=1)\n",
        "\n",
        "# Scale the features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Apply PCA for dimensionality reduction\n",
        "pca = PCA(n_components=2)  # Reduce to 2 components for easy plotting\n",
        "X_pca = pca.fit_transform(X_scaled)\n",
        "\n",
        "# Determine optimal number of clusters for K-means using Silhouette Score\n",
        "silhouette_scores = []\n",
        "for n_clusters in range(2, 6):  # Try different numbers of clusters\n",
        "    kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)\n",
        "    cluster_labels = kmeans.fit_predict(X_pca)\n",
        "    silhouette_avg = silhouette_score(X_pca, cluster_labels)\n",
        "    silhouette_scores.append(silhouette_avg)\n",
        "\n",
        "# Select the number of clusters with the highest Silhouette Score\n",
        "optimal_n_clusters = range(2, 6)[silhouette_scores.index(max(silhouette_scores))]\n",
        "\n",
        "# Perform K-means clustering with optimal number of clusters\n",
        "kmeans = KMeans(n_clusters=optimal_n_clusters, random_state=42, n_init=10)\n",
        "kmeans_clusters = kmeans.fit_predict(X_pca)\n",
        "\n",
        "# Determine optimal DBSCAN parameters using Silhouette Score\n",
        "best_dbscan_score = -1\n",
        "optimal_eps = None\n",
        "optimal_min_samples = None\n",
        "\n",
        "for eps in [0.1, 0.5, 1.0, 1.5]:\n",
        "    for min_samples in [5, 10, 15]:\n",
        "        dbscan = DBSCAN(eps=eps, min_samples=min_samples)\n",
        "        dbscan_clusters = dbscan.fit_predict(X_pca)\n",
        "        \n",
        "        # DBSCAN may result in all points being noise (cluster -1).  Need at least 2 clusters to calculate silhouette score\n",
        "        if len(set(dbscan_clusters)) > 1:\n",
        "            dbscan_score = silhouette_score(X_pca, dbscan_clusters)\n",
        "            if dbscan_score > best_dbscan_score:\n",
        "                best_dbscan_score = dbscan_score\n",
        "                optimal_eps = eps\n",
        "                optimal_min_samples = min_samples\n",
        "\n",
        "# Perform DBSCAN clustering with optimal parameters\n",
        "dbscan = DBSCAN(eps=optimal_eps, min_samples=optimal_min_samples)  # Adjust eps and min_samples as needed\n",
        "dbscan_clusters = dbscan.fit_predict(X_pca)\n",
        "\n",
        "# Create a DataFrame for plotting\n",
        "pca_df = pd.DataFrame(data=X_pca, columns=['PCA1', 'PCA2'])\n",
        "pca_df['KMeans Cluster'] = kmeans_clusters\n",
        "pca_df['DBSCAN Cluster'] = dbscan_clusters\n",
        "pca_df['Bot Category'] = y.map({0: 'Likely Human', 1: 'Possible Bot', 2: 'Likely Bot'}).values  # Add actual bot categories for comparison\n",
        "\n",
        "# Get the loading vectors\n",
        "loadings = pca.components_\n",
        "\n",
        "# Determine the most important features for each component\n",
        "feature_names = X.columns\n",
        "pc1_loadings = pd.Series(loadings[0], index=feature_names)\n",
        "pc2_loadings = pd.Series(loadings[1], index=feature_names)\n",
        "\n",
        "# Identify top features for each component\n",
        "pc1_top_features = pc1_loadings.abs().nlargest(3).index.tolist()\n",
        "pc2_top_features = pc2_loadings.abs().nlargest(3).index.tolist()\n",
        "\n",
        "# Label the principal components\n",
        "pc1_label = f\"PC1 ({', '.join(pc1_top_features)})\"\n",
        "pc2_label = f\"PC2 ({', '.join(pc2_top_features)})\""
      ],
      "id": "9c094aea",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Visualize the KMeans clusters\n",
        "plt.figure(figsize=(12, 10))\n",
        "plt.subplot(2, 1, 1)\n",
        "sns.scatterplot(x='PCA1', y='PCA2', hue='KMeans Cluster', style='Bot Category', data=pca_df, palette='viridis', alpha=0.7, s=100)\n",
        "plt.title('K-Means Clustering of User Features')\n",
        "plt.xlabel(pc1_label)\n",
        "plt.ylabel(pc2_label)\n",
        "\n",
        "# Visualize the DBSCAN clusters\n",
        "plt.subplot(2, 1, 2)\n",
        "sns.scatterplot(x='PCA1', y='PCA2', hue='DBSCAN Cluster', style='Bot Category', data=pca_df, palette='viridis', alpha=0.7, s=100)\n",
        "plt.title('DBSCAN Clustering of User Features')\n",
        "plt.xlabel(pc1_label)\n",
        "plt.ylabel(pc2_label)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "id": "8d798113",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "from nltk.sentiment import SentimentIntensityAnalyzer\n",
        "from textblob import TextBlob\n",
        "import re\n",
        "from collections import Counter\n",
        "from wordcloud import WordCloud\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "import string\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "import textstat\n",
        "from nrclex import NRCLex\n",
        "\n",
        "# Import necessary libraries\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Download necessary NLTK resources\n",
        "nltk.download('punkt', quiet=True)\n",
        "nltk.download('stopwords', quiet=True)\n",
        "nltk.download('vader_lexicon', quiet=True)\n",
        "\n",
        "# Create a filter removing AutoModerator and separating humans from bots\n",
        "ml_features_filtered = ml_features[ml_features['comment_author'] != 'AutoModerator'].copy()\n",
        "\n",
        "# Add a 'user_type' column\n",
        "ml_features_filtered['user_type'] = 'Human'\n",
        "ml_features_filtered.loc[ml_features_filtered['possible_bot'] == 1, 'user_type'] = 'Bot'\n",
        "ml_features_filtered.loc[ml_features_filtered['very_likely_bot'] == 1, 'user_type'] = 'Bot'\n",
        "\n",
        "# VADER Sentiment Analysis\n",
        "analyzer = SentimentIntensityAnalyzer()\n",
        "\n",
        "# Add sentiment scores\n",
        "ml_features_filtered['vader_compound'] = ml_features_filtered['comment_body'].apply(lambda x: analyzer.polarity_scores(x)['compound'])\n",
        "ml_features_filtered['vader_pos'] = ml_features_filtered['comment_body'].apply(lambda x: analyzer.polarity_scores(x)['pos'])\n",
        "ml_features_filtered['vader_neg'] = ml_features_filtered['comment_body'].apply(lambda x: analyzer.polarity_scores(x)['neg'])\n",
        "ml_features_filtered['vader_neu'] = ml_features_filtered['comment_body'].apply(lambda x: analyzer.polarity_scores(x)['neu'])\n",
        "\n",
        "# Calculate text complexity metrics\n",
        "ml_features_filtered['readability_score'] = ml_features_filtered['comment_body'].apply(lambda x: textstat.flesch_reading_ease(x))\n",
        "ml_features_filtered['complexity_score'] = ml_features_filtered['comment_body'].apply(lambda x: textstat.gunning_fog(x))\n",
        "\n",
        "# Function to detect slang or informal language\n",
        "def contains_slang(text):\n",
        "    # Simple slang detection based on common patterns\n",
        "    slang_patterns = [r'\\blol\\b', r'\\bomg\\b', r'\\bbtw\\b', r'\\bidk\\b', r'\\bimo\\b', r'\\bfyi\\b', \n",
        "                      r'\\bsmh\\b', r'\\bwtf\\b', r'\\baf\\b', r'\\bfr\\b', r'\\byolo\\b', r'\\btbh\\b',\n",
        "                      r'\\brofl\\b', r'\\blmao\\b', r'\\blmfao\\b', r'\\bbrb\\b', r'\\bafaik\\b',\n",
        "                      r'\\bftw\\b', r'\\bfml\\b', r'\\bomfg\\b', r'\\bidc\\b', r'\\bimho\\b']\n",
        "    \n",
        "    for pattern in slang_patterns:\n",
        "        if re.search(pattern, text.lower()):\n",
        "            return 1\n",
        "    return 0\n",
        "\n",
        "# Function to count exclamation and question marks\n",
        "def count_punctuation(text):\n",
        "    exclamation_count = text.count('!')\n",
        "    question_count = text.count('?')\n",
        "    return exclamation_count, question_count\n",
        "\n",
        "# Apply the slang detection and punctuation counting\n",
        "ml_features_filtered['contains_slang'] = ml_features_filtered['comment_body'].apply(contains_slang)\n",
        "ml_features_filtered['exclamation_count'] = ml_features_filtered['comment_body'].apply(lambda x: count_punctuation(x)[0])\n",
        "ml_features_filtered['question_count'] = ml_features_filtered['comment_body'].apply(lambda x: count_punctuation(x)[1])\n",
        "\n",
        "# Emotion Detection using NRCLex\n",
        "def extract_emotions(text):\n",
        "    emotion_scores = NRCLex(text).affect_frequencies\n",
        "    return emotion_scores\n",
        "\n",
        "# Extract a sample due to computational constraints\n",
        "sample_size = min(1000, len(ml_features_filtered))\n",
        "emotions_sample = ml_features_filtered.sample(sample_size, random_state=42)\n",
        "\n",
        "# Apply emotion extraction\n",
        "emotions_df = pd.DataFrame([extract_emotions(text) for text in emotions_sample['comment_body']])\n",
        "emotions_sample = pd.concat([emotions_sample.reset_index(drop=True), emotions_df.reset_index(drop=True)], axis=1)\n",
        "\n",
        "# Create visualization for sentiment comparison\n",
        "plt.figure(figsize=(16, 12))\n",
        "\n",
        "# 1. VADER Sentiment Distribution\n",
        "plt.subplot(2, 2, 1)\n",
        "sns.boxplot(x='user_type', y='vader_compound', data=ml_features_filtered)\n",
        "plt.title('VADER Sentiment Scores by User Type')\n",
        "plt.xlabel('User Type')\n",
        "plt.ylabel('Compound Sentiment Score')\n",
        "\n",
        "# 2. Emotion Comparison\n",
        "plt.subplot(2, 2, 2)\n",
        "emotion_cols = ['fear', 'anger', 'anticipation', 'trust', 'surprise', 'sadness', 'disgust', 'joy']\n",
        "emotions_by_type = emotions_sample.groupby('user_type')[emotion_cols].mean()\n",
        "emotions_by_type.T.plot(kind='bar', ax=plt.gca())\n",
        "plt.title('Average Emotion Intensity by User Type')\n",
        "plt.xlabel('Emotion')\n",
        "plt.ylabel('Average Intensity')\n",
        "plt.xticks(rotation=45)\n",
        "plt.legend(title='User Type')\n",
        "\n",
        "# 3. Text Complexity\n",
        "plt.subplot(2, 2, 3)\n",
        "sns.boxplot(x='user_type', y='readability_score', data=ml_features_filtered)\n",
        "plt.title('Text Readability by User Type')\n",
        "plt.xlabel('User Type')\n",
        "plt.ylabel('Flesch Reading Ease Score')\n",
        "\n",
        "# 4. Slang Usage\n",
        "plt.subplot(2, 2, 4)\n",
        "slang_by_type = ml_features_filtered.groupby('user_type')['contains_slang'].mean()\n",
        "slang_by_type.plot(kind='bar', ax=plt.gca())\n",
        "plt.title('Slang Usage by User Type')\n",
        "plt.xlabel('User Type')\n",
        "plt.ylabel('Proportion of Comments with Slang')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Extract common words by user type\n",
        "def get_common_words(texts, n=20):\n",
        "    # Tokenize and clean\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    stop_words.update(['would', 'could', 'also', 'one', 'like', 'get', 'even', 'say', 'said', 'make', 'think', 'know'])\n",
        "    \n",
        "    words = []\n",
        "    for text in texts:\n",
        "        tokens = word_tokenize(text.lower())\n",
        "        # Remove stopwords, punctuation, and non-alphabetic tokens\n",
        "        words.extend([word for word in tokens if word not in stop_words \n",
        "                     and word not in string.punctuation \n",
        "                     and word.isalpha() \n",
        "                     and len(word) > 2]) #this line filters out words of length 3 or more\n",
        "    \n",
        "    return Counter(words).most_common(n)\n",
        "\n",
        "# Get most common words for humans and bots\n",
        "human_texts = ml_features_filtered[ml_features_filtered['user_type'] == 'Human']['comment_body'].tolist()\n",
        "bot_texts = ml_features_filtered[ml_features_filtered['user_type'] == 'Bot']['comment_body'].tolist()\n",
        "\n",
        "human_common_words = get_common_words(human_texts)\n",
        "bot_common_words = get_common_words(bot_texts)\n",
        "\n",
        "# Create word clouds\n",
        "plt.figure(figsize=(16, 8))\n",
        "\n",
        "# Word cloud for humans\n",
        "plt.subplot(1, 2, 1)\n",
        "human_wordcloud = WordCloud(width=800, height=400, background_color='white', \n",
        "                           max_words=100, colormap='viridis', min_word_length=3).generate(' '.join(human_texts))\n",
        "plt.imshow(human_wordcloud, interpolation='bilinear')\n",
        "plt.title('Word Cloud for Human Comments')\n",
        "plt.axis('off')\n",
        "\n",
        "# Word cloud for bots\n",
        "plt.subplot(1, 2, 2)\n",
        "bot_wordcloud = WordCloud(width=800, height=400, background_color='white', \n",
        "                         max_words=100, colormap='plasma', min_word_length=3).generate(' '.join(bot_texts))\n",
        "plt.imshow(bot_wordcloud, interpolation='bilinear')\n",
        "plt.title('Word Cloud for Bot Comments')\n",
        "plt.axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Compare linguistic style metrics\n",
        "plt.figure(figsize=(16, 12))\n",
        "\n",
        "# 1. Comment Length Comparison\n",
        "plt.subplot(2, 2, 1)\n",
        "sns.boxplot(x='user_type', y='comment_length', data=ml_features_filtered)\n",
        "plt.title('Comment Length by User Type')\n",
        "plt.xlabel('User Type')\n",
        "plt.ylabel('Comment Length (Characters)')\n",
        "\n",
        "# 2. Complexity Score Comparison\n",
        "plt.subplot(2, 2, 2)\n",
        "sns.boxplot(x='user_type', y='complexity_score', data=ml_features_filtered)\n",
        "plt.title('Text Complexity by User Type')\n",
        "plt.xlabel('User Type')\n",
        "plt.ylabel('Gunning Fog Index')\n",
        "\n",
        "# 3. Exclamation Mark Usage\n",
        "plt.subplot(2, 2, 3)\n",
        "sns.boxplot(x='user_type', y='exclamation_count', data=ml_features_filtered)\n",
        "plt.title('Exclamation Mark Usage by User Type')\n",
        "plt.xlabel('User Type')\n",
        "plt.ylabel('Number of Exclamation Marks')\n",
        "\n",
        "# 4. Question Mark Usage\n",
        "plt.subplot(2, 2, 4)\n",
        "sns.boxplot(x='user_type', y='question_count', data=ml_features_filtered)\n",
        "plt.title('Question Mark Usage by User Type')\n",
        "plt.xlabel('User Type')\n",
        "plt.ylabel('Number of Question Marks')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Generate summary report\n",
        "human_sentiment = ml_features_filtered[ml_features_filtered['user_type'] == 'Human']['vader_compound'].mean()\n",
        "bot_sentiment = ml_features_filtered[ml_features_filtered['user_type'] == 'Bot']['vader_compound'].mean()\n",
        "\n",
        "human_emotions = emotions_sample[emotions_sample['user_type'] == 'Human'][emotion_cols].mean()\n",
        "bot_emotions = emotions_sample[emotions_sample['user_type'] == 'Bot'][emotion_cols].mean()\n",
        "\n",
        "# Print human top emotions\n",
        "human_top_emotions = human_emotions.sort_values(ascending=False).head(3)\n",
        "bot_top_emotions = bot_emotions.sort_values(ascending=False).head(3)\n",
        "\n",
        "print(\"\\n=== SENTIMENT ANALYSIS SUMMARY ===\\n\")\n",
        "print(f\"Human Average Sentiment: {human_sentiment:.4f}\")\n",
        "print(f\"Bot Average Sentiment: {bot_sentiment:.4f}\")\n",
        "print(\"\\nDominant Human Emotions:\")\n",
        "for emotion, score in human_top_emotions.items():\n",
        "    print(f\"- {emotion.capitalize()}: {score:.4f}\")\n",
        "print(\"\\nDominant Bot Emotions:\")\n",
        "for emotion, score in bot_top_emotions.items():\n",
        "    print(f\"- {emotion.capitalize()}: {score:.4f}\")\n",
        "\n",
        "print(\"\\nTop 10 Common Words in Human Comments:\")\n",
        "for word, count in human_common_words[:10]:\n",
        "    print(f\"- {word}: {count}\")\n",
        "\n",
        "print(\"\\nTop 10 Common Words in Bot Comments:\")\n",
        "for word, count in bot_common_words[:10]:\n",
        "    print(f\"- {word}: {count}\")\n",
        "\n",
        "print(\"\\nLinguistic Style Comparison:\")\n",
        "print(f\"Human Average Readability Score: {ml_features_filtered[ml_features_filtered['user_type'] == 'Human']['readability_score'].mean():.2f}\")\n",
        "print(f\"Bot Average Readability Score: {ml_features_filtered[ml_features_filtered['user_type'] == 'Bot']['readability_score'].mean():.2f}\")\n",
        "print(f\"Human Average Complexity Score: {ml_features_filtered[ml_features_filtered['user_type'] == 'Human']['complexity_score'].mean():.2f}\")\n",
        "print(f\"Bot Average Complexity Score: {ml_features_filtered[ml_features_filtered['user_type'] == 'Bot']['complexity_score'].mean():.2f}\")\n",
        "print(f\"Human Slang Usage Rate: {ml_features_filtered[ml_features_filtered['user_type'] == 'Human']['contains_slang'].mean():.2%}\")\n",
        "print(f\"Bot Slang Usage Rate: {ml_features_filtered[ml_features_filtered['user_type'] == 'Bot']['contains_slang'].mean():.2%}\")"
      ],
      "id": "11ae9b3c",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "from nltk.sentiment import SentimentIntensityAnalyzer\n",
        "from textblob import TextBlob\n",
        "import re\n",
        "from collections import Counter\n",
        "from wordcloud import WordCloud\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "import string\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "import textstat\n",
        "from nrclex import NRCLex\n",
        "\n",
        "# Import necessary libraries\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Download necessary NLTK resources\n",
        "nltk.download('punkt', quiet=True)\n",
        "nltk.download('stopwords', quiet=True)\n",
        "nltk.download('vader_lexicon', quiet=True)\n",
        "\n",
        "# Create a filter removing AutoModerator first\n",
        "recent_user_comments_filtered = recent_user_comments[recent_user_comments['author'] != 'AutoModerator'].copy()\n",
        "\n",
        "# Create a new column 'user_type' in recent_user_comments_filtered\n",
        "recent_user_comments_filtered['user_type'] = 'Human'  # Default to Human\n",
        "\n",
        "# Merge ml_features with recent_user_comments_filtered on 'author' to identify bots\n",
        "recent_user_comments_filtered = pd.merge(\n",
        "    recent_user_comments_filtered,\n",
        "    ml_features[['comment_author', 'possible_bot', 'very_likely_bot']],\n",
        "    left_on='author',\n",
        "    right_on='comment_author',\n",
        "    how='left'\n",
        ")\n",
        "\n",
        "# Remove duplicate rows based on 'comment_id', keeping only the first occurrence\n",
        "recent_user_comments_filtered = recent_user_comments_filtered.drop_duplicates(subset='comment_id', keep='first')\n",
        "\n",
        "# Fill NaN values in 'possible_bot' and 'very_likely_bot' with 0 (not a bot)\n",
        "recent_user_comments_filtered['possible_bot'] = recent_user_comments_filtered['possible_bot'].fillna(0).astype(int)\n",
        "recent_user_comments_filtered['very_likely_bot'] = recent_user_comments_filtered['very_likely_bot'].fillna(0).astype(int)\n",
        "\n",
        "# Update 'user_type' based on bot classifications\n",
        "recent_user_comments_filtered.loc[recent_user_comments_filtered['possible_bot'] == 1, 'user_type'] = 'Bot'\n",
        "recent_user_comments_filtered.loc[recent_user_comments_filtered['very_likely_bot'] == 1, 'user_type'] = 'Bot'\n",
        "\n",
        "# Drop unnecessary columns after the merge\n",
        "recent_user_comments_filtered = recent_user_comments_filtered.drop(['comment_author', 'possible_bot', 'very_likely_bot'], axis=1)\n",
        "\n",
        "# VADER Sentiment Analysis\n",
        "analyzer = SentimentIntensityAnalyzer()\n",
        "\n",
        "# Add sentiment scores\n",
        "recent_user_comments_filtered['vader_compound'] = recent_user_comments_filtered['body'].apply(lambda x: analyzer.polarity_scores(x)['compound'])\n",
        "recent_user_comments_filtered['vader_pos'] = recent_user_comments_filtered['body'].apply(lambda x: analyzer.polarity_scores(x)['pos'])\n",
        "recent_user_comments_filtered['vader_neg'] = recent_user_comments_filtered['body'].apply(lambda x: analyzer.polarity_scores(x)['neg'])\n",
        "recent_user_comments_filtered['vader_neu'] = recent_user_comments_filtered['body'].apply(lambda x: analyzer.polarity_scores(x)['neu'])\n",
        "\n",
        "# Calculate text complexity metrics\n",
        "recent_user_comments_filtered['comment_length'] = recent_user_comments_filtered['body'].apply(len)\n",
        "recent_user_comments_filtered['readability_score'] = recent_user_comments_filtered['body'].apply(lambda x: textstat.flesch_reading_ease(x))\n",
        "recent_user_comments_filtered['complexity_score'] = recent_user_comments_filtered['body'].apply(lambda x: textstat.gunning_fog(x))\n",
        "\n",
        "# Function to detect slang or informal language\n",
        "def contains_slang(text):\n",
        "    # Simple slang detection based on common patterns\n",
        "    slang_patterns = [r'\\blol\\b', r'\\bomg\\b', r'\\bbtw\\b', r'\\bidk\\b', r'\\bimo\\b', r'\\bfyi\\b', \n",
        "                      r'\\bsmh\\b', r'\\bwtf\\b', r'\\baf\\b', r'\\bfr\\b', r'\\byolo\\b', r'\\btbh\\b',\n",
        "                      r'\\brofl\\b', r'\\blmao\\b', r'\\blmfao\\b', r'\\bbrb\\b', r'\\bafaik\\b',\n",
        "                      r'\\bftw\\b', r'\\bfml\\b', r'\\bomfg\\b', r'\\bidc\\b', r'\\bimho\\b']\n",
        "    \n",
        "    for pattern in slang_patterns:\n",
        "        if re.search(pattern, text.lower()):\n",
        "            return 1\n",
        "    return 0\n",
        "\n",
        "# Function to count exclamation and question marks\n",
        "def count_punctuation(text):\n",
        "    exclamation_count = text.count('!')\n",
        "    question_count = text.count('?')\n",
        "    return exclamation_count, question_count\n",
        "\n",
        "# Apply the slang detection and punctuation counting\n",
        "recent_user_comments_filtered['contains_slang'] = recent_user_comments_filtered['body'].apply(contains_slang)\n",
        "recent_user_comments_filtered['exclamation_count'] = recent_user_comments_filtered['body'].apply(lambda x: count_punctuation(x)[0])\n",
        "recent_user_comments_filtered['question_count'] = recent_user_comments_filtered['body'].apply(lambda x: count_punctuation(x)[1])\n",
        "\n",
        "# Emotion Detection using NRCLex\n",
        "def extract_emotions(text):\n",
        "    emotion_scores = NRCLex(text).affect_frequencies\n",
        "    return emotion_scores\n",
        "\n",
        "# Extract a sample due to computational constraints\n",
        "sample_size = min(1000, len(recent_user_comments_filtered))\n",
        "emotions_sample = recent_user_comments_filtered.sample(sample_size, random_state=42)\n",
        "\n",
        "# Apply emotion extraction\n",
        "emotions_df = pd.DataFrame([extract_emotions(text) for text in emotions_sample['body']])\n",
        "emotions_sample = pd.concat([emotions_sample.reset_index(drop=True), emotions_df.reset_index(drop=True)], axis=1)\n",
        "\n",
        "# Create visualization for sentiment comparison\n",
        "plt.figure(figsize=(16, 12))\n",
        "\n",
        "# 1. VADER Sentiment Distribution\n",
        "plt.subplot(2, 2, 1)\n",
        "sns.boxplot(x='user_type', y='vader_compound', data=recent_user_comments_filtered)\n",
        "plt.title('VADER Sentiment Scores by User Type')\n",
        "plt.xlabel('User Type')\n",
        "plt.ylabel('Compound Sentiment Score')\n",
        "\n",
        "# 2. Emotion Comparison\n",
        "plt.subplot(2, 2, 2)\n",
        "emotion_cols = ['fear', 'anger', 'anticipation', 'trust', 'surprise', 'sadness', 'disgust', 'joy']\n",
        "emotions_by_type = emotions_sample.groupby('user_type')[emotion_cols].mean()\n",
        "emotions_by_type.T.plot(kind='bar', ax=plt.gca())\n",
        "plt.title('Average Emotion Intensity by User Type')\n",
        "plt.xlabel('Emotion')\n",
        "plt.ylabel('Average Intensity')\n",
        "plt.xticks(rotation=45)\n",
        "plt.legend(title='User Type')\n",
        "\n",
        "# 3. Text Complexity\n",
        "plt.subplot(2, 2, 3)\n",
        "sns.boxplot(x='user_type', y='readability_score', data=recent_user_comments_filtered)\n",
        "plt.title('Text Readability by User Type')\n",
        "plt.xlabel('User Type')\n",
        "plt.ylabel('Flesch Reading Ease Score')\n",
        "\n",
        "# 4. Slang Usage\n",
        "plt.subplot(2, 2, 4)\n",
        "slang_by_type = recent_user_comments_filtered.groupby('user_type')['contains_slang'].mean()\n",
        "slang_by_type.plot(kind='bar', ax=plt.gca())\n",
        "plt.title('Slang Usage by User Type')\n",
        "plt.xlabel('User Type')\n",
        "plt.ylabel('Proportion of Comments with Slang')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Extract common words by user type\n",
        "def get_common_words(texts, n=20):\n",
        "    # Tokenize and clean\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    stop_words.update(['would', 'could', 'also', 'one', 'like', 'get', 'even', 'say', 'said', 'make', 'think', 'know'])\n",
        "    \n",
        "    words = []\n",
        "    for text in texts:\n",
        "        tokens = word_tokenize(text.lower())\n",
        "        # Remove stopwords, punctuation, and non-alphabetic tokens\n",
        "        words.extend([word for word in tokens if word not in stop_words \n",
        "                     and word not in string.punctuation \n",
        "                     and word.isalpha() \n",
        "                     and len(word) > 2])\n",
        "    \n",
        "    return Counter(words).most_common(n)\n",
        "\n",
        "# Get most common words for humans and bots\n",
        "human_texts = recent_user_comments_filtered[recent_user_comments_filtered['user_type'] == 'Human']['body'].tolist()\n",
        "bot_texts = recent_user_comments_filtered[recent_user_comments_filtered['user_type'] == 'Bot']['body'].tolist()\n",
        "\n",
        "human_common_words = get_common_words(human_texts)\n",
        "bot_common_words = get_common_words(bot_texts)\n",
        "\n",
        "# Create word clouds\n",
        "plt.figure(figsize=(16, 8))\n",
        "\n",
        "# Word cloud for humans\n",
        "plt.subplot(1, 2, 1)\n",
        "human_wordcloud = WordCloud(width=800, height=400, background_color='white', \n",
        "                           max_words=100, colormap='viridis', min_word_length=3).generate(' '.join(human_texts))\n",
        "plt.imshow(human_wordcloud, interpolation='bilinear')\n",
        "plt.title('Word Cloud for Human Comments')\n",
        "plt.axis('off')\n",
        "\n",
        "# Word cloud for bots\n",
        "plt.subplot(1, 2, 2)\n",
        "bot_wordcloud = WordCloud(width=800, height=400, background_color='white', \n",
        "                         max_words=100, colormap='plasma', min_word_length=3).generate(' '.join(bot_texts))\n",
        "plt.imshow(bot_wordcloud, interpolation='bilinear')\n",
        "plt.title('Word Cloud for Bot Comments')\n",
        "plt.axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Compare linguistic style metrics\n",
        "plt.figure(figsize=(16, 12))\n",
        "\n",
        "# 1. Comment Length Comparison\n",
        "plt.subplot(2, 2, 1)\n",
        "sns.boxplot(x='user_type', y='comment_length', data=recent_user_comments_filtered)\n",
        "plt.title('Comment Length by User Type')\n",
        "plt.xlabel('User Type')\n",
        "plt.ylabel('Comment Length (Characters)')\n",
        "\n",
        "# 2. Complexity Score Comparison\n",
        "plt.subplot(2, 2, 2)\n",
        "sns.boxplot(x='user_type', y='complexity_score', data=recent_user_comments_filtered)\n",
        "plt.title('Text Complexity by User Type')\n",
        "plt.xlabel('User Type')\n",
        "plt.ylabel('Gunning Fog Index')\n",
        "\n",
        "# 3. Exclamation Mark Usage\n",
        "plt.subplot(2, 2, 3)\n",
        "sns.boxplot(x='user_type', y='exclamation_count', data=recent_user_comments_filtered)\n",
        "plt.title('Exclamation Mark Usage by User Type')\n",
        "plt.xlabel('User Type')\n",
        "plt.ylabel('Number of Exclamation Marks')\n",
        "\n",
        "# 4. Question Mark Usage\n",
        "plt.subplot(2, 2, 4)\n",
        "sns.boxplot(x='user_type', y='question_count', data=recent_user_comments_filtered)\n",
        "plt.title('Question Mark Usage by User Type')\n",
        "plt.xlabel('User Type')\n",
        "plt.ylabel('Number of Question Marks')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Generate summary report\n",
        "human_sentiment = recent_user_comments_filtered[recent_user_comments_filtered['user_type'] == 'Human']['vader_compound'].mean()\n",
        "bot_sentiment = recent_user_comments_filtered[recent_user_comments_filtered['user_type'] == 'Bot']['vader_compound'].mean()\n",
        "\n",
        "human_emotions = emotions_sample[emotions_sample['user_type'] == 'Human'][emotion_cols].mean()\n",
        "bot_emotions = emotions_sample[emotions_sample['user_type'] == 'Bot'][emotion_cols].mean()\n",
        "\n",
        "# Print human top emotions\n",
        "human_top_emotions = human_emotions.sort_values(ascending=False).head(3)\n",
        "bot_top_emotions = bot_emotions.sort_values(ascending=False).head(3)\n",
        "\n",
        "print(\"\\n=== SENTIMENT ANALYSIS SUMMARY ===\\n\")\n",
        "print(f\"Human Average Sentiment: {human_sentiment:.4f}\")\n",
        "print(f\"Bot Average Sentiment: {bot_sentiment:.4f}\")\n",
        "print(\"\\nDominant Human Emotions:\")\n",
        "for emotion, score in human_top_emotions.items():\n",
        "    print(f\"- {emotion.capitalize()}: {score:.4f}\")\n",
        "print(\"\\nDominant Bot Emotions:\")\n",
        "for emotion, score in bot_top_emotions.items():\n",
        "    print(f\"- {emotion.capitalize()}: {score:.4f}\")\n",
        "\n",
        "print(\"\\nTop 10 Common Words in Human Comments:\")\n",
        "for word, count in human_common_words[:10]:\n",
        "    print(f\"- {word}: {count}\")\n",
        "\n",
        "print(\"\\nTop 10 Common Words in Bot Comments:\")\n",
        "for word, count in bot_common_words[:10]:\n",
        "    print(f\"- {word}: {count}\")\n",
        "\n",
        "print(\"\\nLinguistic Style Comparison:\")\n",
        "print(f\"Human Average Readability Score: {recent_user_comments_filtered[recent_user_comments_filtered['user_type'] == 'Human']['readability_score'].mean():.2f}\")\n",
        "print(f\"Bot Average Readability Score: {recent_user_comments_filtered[recent_user_comments_filtered['user_type'] == 'Bot']['readability_score'].mean():.2f}\")\n",
        "print(f\"Human Average Complexity Score: {recent_user_comments_filtered[recent_user_comments_filtered['user_type'] == 'Human']['complexity_score'].mean():.2f}\")\n",
        "print(f\"Bot Average Complexity Score: {recent_user_comments_filtered[recent_user_comments_filtered['user_type'] == 'Bot']['complexity_score'].mean():.2f}\")\n",
        "print(f\"Human Slang Usage Rate: {recent_user_comments_filtered[recent_user_comments_filtered['user_type'] == 'Human']['contains_slang'].mean():.2%}\")\n",
        "print(f\"Bot Slang Usage Rate: {recent_user_comments_filtered[recent_user_comments_filtered['user_type'] == 'Bot']['contains_slang'].mean():.2%}\")"
      ],
      "id": "165cdd8d",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "from nltk.sentiment import SentimentIntensityAnalyzer\n",
        "from textblob import TextBlob\n",
        "import re\n",
        "from collections import Counter\n",
        "from wordcloud import WordCloud\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "import string\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "import textstat\n",
        "from nrclex import NRCLex\n",
        "\n",
        "# Import necessary libraries\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Download necessary NLTK resources\n",
        "nltk.download('punkt', quiet=True)\n",
        "nltk.download('stopwords', quiet=True)\n",
        "nltk.download('vader_lexicon', quiet=True)\n",
        "\n",
        "# Sentiment Analysis by Subreddit\n",
        "analyzer = SentimentIntensityAnalyzer()\n",
        "processed_comments['vader_compound'] = processed_comments['comment_body'].apply(lambda x: analyzer.polarity_scores(x)['compound'])\n",
        "\n",
        "# Group by subreddit and calculate average sentiment\n",
        "subreddit_sentiment = processed_comments.groupby('subreddit')['vader_compound'].mean().sort_values(ascending=False)\n",
        "\n",
        "# Plotting the sentiment by subreddit\n",
        "plt.figure(figsize=(12, 8))\n",
        "subreddit_sentiment.plot(kind='bar')\n",
        "plt.title('Average Sentiment by Subreddit')\n",
        "plt.xlabel('Subreddit')\n",
        "plt.ylabel('Average Compound Sentiment Score')\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Word Clouds by Subreddit\n",
        "def generate_word_cloud(text, title):\n",
        "    wordcloud = WordCloud(width=800, height=400, background_color='white', min_word_length=3).generate(text)\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    plt.imshow(wordcloud, interpolation='bilinear')\n",
        "    plt.title(title)\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "# Group comments by subreddit\n",
        "grouped_comments = processed_comments.groupby('subreddit')['comment_body'].apply(lambda x: ' '.join(x))\n",
        "\n",
        "# Generate word clouds for top subreddits\n",
        "top_n = 5  # Number of top subreddits to display\n",
        "top_subreddits = grouped_comments.head(top_n)\n",
        "\n",
        "for subreddit, text in top_subreddits.items():\n",
        "    generate_word_cloud(text, f'Word Cloud for /r/{subreddit}')"
      ],
      "id": "b7c7ce09",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "\n",
        "# Create subreddit cross-similarity heatmaps\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Group comments by subreddit\n",
        "subreddit_texts = processed_comments.groupby('subreddit')['comment_body'].apply(lambda x: ' '.join(x))\n",
        "\n",
        "# Get the top subreddits by comment count\n",
        "top_subreddits = processed_comments['subreddit'].value_counts().head(15).index.tolist()\n",
        "\n",
        "# Filter to include only top subreddits\n",
        "filtered_texts = subreddit_texts[subreddit_texts.index.isin(top_subreddits)]\n",
        "\n",
        "# Calculate TF-IDF vectors for each subreddit's combined text\n",
        "vectorizer = TfidfVectorizer(max_features=5000, stop_words='english', min_df=2)\n",
        "tfidf_matrix = vectorizer.fit_transform(filtered_texts)\n",
        "\n",
        "# Calculate cosine similarity between subreddits\n",
        "similarity_matrix = cosine_similarity(tfidf_matrix)\n",
        "\n",
        "# Create a DataFrame for the similarity matrix\n",
        "similarity_df = pd.DataFrame(\n",
        "    similarity_matrix, \n",
        "    index=filtered_texts.index, \n",
        "    columns=filtered_texts.index\n",
        ")\n",
        "\n",
        "# Plot the heatmap\n",
        "plt.figure(figsize=(12, 10))\n",
        "sns.heatmap(similarity_df, annot=True, cmap='YlGnBu', vmin=0.5, vmax=1, linewidths=0.5)\n",
        "plt.title('Cross-Subreddit Content Similarity Heatmap')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Extract the most distinguishing terms for each subreddit\n",
        "feature_names = np.array(vectorizer.get_feature_names_out())\n",
        "\n",
        "def get_top_features(tfidf_matrix, feature_names, top_n=10):\n",
        "    \"\"\"Get the top N most distinctive features for each subreddit\"\"\"\n",
        "    top_features = {}\n",
        "    \n",
        "    for i, subreddit in enumerate(filtered_texts.index):\n",
        "        # Get the TF-IDF scores for this subreddit\n",
        "        tfidf_scores = tfidf_matrix[i].toarray().flatten()\n",
        "        \n",
        "        # Get indices of top N features\n",
        "        top_indices = tfidf_scores.argsort()[-top_n:][::-1]\n",
        "        \n",
        "        # Get feature names and scores\n",
        "        top_terms = [(feature_names[idx], tfidf_scores[idx]) for idx in top_indices]\n",
        "        \n",
        "        top_features[subreddit] = top_terms\n",
        "    \n",
        "    return top_features\n",
        "\n",
        "subreddit_top_terms = get_top_features(tfidf_matrix, feature_names)"
      ],
      "id": "b74dbff6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from google import genai\n",
        "from google.genai import types\n",
        "from wordcloud import WordCloud\n",
        "import random\n",
        "\n",
        "# ----- Step 1: Extract Top 5 Subreddits from ml_features -----\n",
        "# Assume ml_features is already in your environment.\n",
        "top_subreddits = ml_features['subreddit'].value_counts().head(5).index.tolist()\n",
        "\n",
        "# ----- Step 2: Stratified Sampling ----- \n",
        "sampled_comments = {}\n",
        "sample_size = 100\n",
        "for subreddit in top_subreddits:\n",
        "    subreddit_comments = ml_features[ml_features['subreddit'] == subreddit]['comment_body']\n",
        "    if len(subreddit_comments) > sample_size:\n",
        "        sampled = subreddit_comments.sample(n=sample_size, random_state=42)\n",
        "    else:\n",
        "        sampled = subreddit_comments\n",
        "    sampled_comments[subreddit] = sampled.tolist()\n",
        "\n",
        "# ----- Step 3: Gemini API generate() Function -----\n",
        "def generate(prompt):\n",
        "    client = genai.Client(\n",
        "        api_key=os.getenv(\"GEMINI_API_KEY\"),\n",
        "    )\n",
        "    model = \"gemini-2.0-flash\"\n",
        "    contents = [\n",
        "        types.Content(\n",
        "            role=\"user\",\n",
        "            parts=[\n",
        "                types.Part.from_text(text=prompt),\n",
        "            ],\n",
        "        ),\n",
        "    ]\n",
        "    generate_content_config = types.GenerateContentConfig(\n",
        "        temperature=0,\n",
        "        top_p=0,\n",
        "        top_k=1,\n",
        "        max_output_tokens=8192,\n",
        "        response_mime_type=\"text/plain\",\n",
        "    )\n",
        "    complete_response = \"\"\n",
        "    for chunk in client.models.generate_content_stream(\n",
        "        model=model,\n",
        "        contents=contents,\n",
        "        config=generate_content_config,\n",
        "    ):\n",
        "        complete_response += chunk.text\n",
        "    return complete_response.strip()\n",
        "\n",
        "# ----- Step 4: Query the LLM for Each Subreddit -----\n",
        "subreddit_responses = {}\n",
        "for subreddit, comments in sampled_comments.items():\n",
        "    # Take a random sample of comments if there are too many\n",
        "    if len(\" \".join(comments)) > 4000:\n",
        "        random.seed(42)  # For reproducibility\n",
        "        sampled_comments = random.sample(comments, min(len(comments), 50))\n",
        "        text_blob = \" \".join(sampled_comments)[:4000]\n",
        "    else:\n",
        "        text_blob = \" \".join(comments)[:4000]\n",
        "    prompt = (\n",
        "        f\"Perform sentiment analysis on the following comments from subreddit /r/{subreddit}. \"\n",
        "        \"Identify 20 unique keywords (based exclusively on the text you are fed) that capture the essence of this subreddit (which can later be used for word clouds), and provide a brief sentiment summary (e.g. note if the overall tone is positive, negative, or neutral). \"\n",
        "        \"At the end, on a new separate line, output exactly: 'Keywords: keyword1, keyword2, etc.' followed by a comma-separated list of the keywords, with no extra text.\\n\\nComments:\\n\" \n",
        "        + text_blob\n",
        "    )\n",
        "    response = generate(prompt)\n",
        "    subreddit_responses[subreddit] = response\n",
        "    print(f\"/r/{subreddit} Response:\\n{response}\\n{'-'*60}\\n\")\n",
        "\n",
        "# ----- Step 5: Extract Keywords and Build Word Clouds -----\n",
        "for subreddit, response in subreddit_responses.items():\n",
        "    keywords_line = None\n",
        "    for line in response.splitlines():\n",
        "        if line.strip().startswith(\"Keywords:\"):\n",
        "            keywords_line = line.strip()\n",
        "            break\n",
        "    if keywords_line:\n",
        "        # Remove the \"Keywords:\" prefix and extra spaces, then split by commas.\n",
        "        keywords_part = keywords_line[len(\"Keywords:\"):].strip()\n",
        "        keywords = [kw.strip() for kw in keywords_part.split(\",\") if kw.strip()]\n",
        "    else:\n",
        "        keywords = []\n",
        "    \n",
        "    if keywords:\n",
        "        # Create a text blob from keywords for word cloud generation.\n",
        "        wordcloud_text = \" \".join(keywords)\n",
        "        wc = WordCloud(width=800, height=400, background_color='white', min_word_length=3).generate(wordcloud_text)\n",
        "        plt.figure(figsize=(8, 4))\n",
        "        plt.imshow(wc, interpolation=\"bilinear\")\n",
        "        plt.axis(\"off\")\n",
        "        plt.title(f\"/r/{subreddit} Word Cloud\")\n",
        "        plt.show()\n",
        "    else:\n",
        "        print(f\"No valid keywords extracted for /r/{subreddit}.\")"
      ],
      "id": "dc7d1fc0",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}