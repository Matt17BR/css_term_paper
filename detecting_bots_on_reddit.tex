% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
\PassOptionsToPackage{dvipsnames,svgnames,x11names}{xcolor}
%
\documentclass[
  12pt,
  letterpaper,
  DIV=11,
  numbers=noendperiod]{scrartcl}

\usepackage{amsmath,amssymb}
\usepackage{setspace}
\usepackage{iftex}
\ifPDFTeX
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math}
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
\usepackage{lmodern}
\ifPDFTeX\else  
    % xetex/luatex font selection
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\usepackage[top=1.5cm,bottom=3cm,hmargin=2.5cm]{geometry}
\setlength{\emergencystretch}{3em} % prevent overfull lines
\setcounter{secnumdepth}{5}
% Make \paragraph and \subparagraph free-standing
\makeatletter
\ifx\paragraph\undefined\else
  \let\oldparagraph\paragraph
  \renewcommand{\paragraph}{
    \@ifstar
      \xxxParagraphStar
      \xxxParagraphNoStar
  }
  \newcommand{\xxxParagraphStar}[1]{\oldparagraph*{#1}\mbox{}}
  \newcommand{\xxxParagraphNoStar}[1]{\oldparagraph{#1}\mbox{}}
\fi
\ifx\subparagraph\undefined\else
  \let\oldsubparagraph\subparagraph
  \renewcommand{\subparagraph}{
    \@ifstar
      \xxxSubParagraphStar
      \xxxSubParagraphNoStar
  }
  \newcommand{\xxxSubParagraphStar}[1]{\oldsubparagraph*{#1}\mbox{}}
  \newcommand{\xxxSubParagraphNoStar}[1]{\oldsubparagraph{#1}\mbox{}}
\fi
\makeatother


\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}\usepackage{longtable,booktabs,array}
\usepackage{calc} % for calculating minipage widths
% Correct order of tables after \paragraph or \subparagraph
\usepackage{etoolbox}
\makeatletter
\patchcmd\longtable{\par}{\if@noskipsec\mbox{}\fi\par}{}{}
\makeatother
% Allow footnotes in longtable head/foot
\IfFileExists{footnotehyper.sty}{\usepackage{footnotehyper}}{\usepackage{footnote}}
\makesavenoteenv{longtable}
\usepackage{graphicx}
\makeatletter
\newsavebox\pandoc@box
\newcommand*\pandocbounded[1]{% scales image to fit in text height/width
  \sbox\pandoc@box{#1}%
  \Gscale@div\@tempa{\textheight}{\dimexpr\ht\pandoc@box+\dp\pandoc@box\relax}%
  \Gscale@div\@tempb{\linewidth}{\wd\pandoc@box}%
  \ifdim\@tempb\p@<\@tempa\p@\let\@tempa\@tempb\fi% select the smaller of both
  \ifdim\@tempa\p@<\p@\scalebox{\@tempa}{\usebox\pandoc@box}%
  \else\usebox{\pandoc@box}%
  \fi%
}
% Set default figure placement to htbp
\def\fps@figure{htbp}
\makeatother
% definitions for citeproc citations
\NewDocumentCommand\citeproctext{}{}
\NewDocumentCommand\citeproc{mm}{%
  \begingroup\def\citeproctext{#2}\cite{#1}\endgroup}
\makeatletter
 % allow citations to break across lines
 \let\@cite@ofmt\@firstofone
 % avoid brackets around text for \cite:
 \def\@biblabel#1{}
 \def\@cite#1#2{{#1\if@tempswa , #2\fi}}
\makeatother
\newlength{\cslhangindent}
\setlength{\cslhangindent}{1.5em}
\newlength{\csllabelwidth}
\setlength{\csllabelwidth}{3em}
\newenvironment{CSLReferences}[2] % #1 hanging-indent, #2 entry-spacing
 {\begin{list}{}{%
  \setlength{\itemindent}{0pt}
  \setlength{\leftmargin}{0pt}
  \setlength{\parsep}{0pt}
  % turn on hanging indent if param 1 is 1
  \ifodd #1
   \setlength{\leftmargin}{\cslhangindent}
   \setlength{\itemindent}{-1\cslhangindent}
  \fi
  % set entry spacing
  \setlength{\itemsep}{#2\baselineskip}}}
 {\end{list}}
\usepackage{calc}
\newcommand{\CSLBlock}[1]{\hfill\break\parbox[t]{\linewidth}{\strut\ignorespaces#1\strut}}
\newcommand{\CSLLeftMargin}[1]{\parbox[t]{\csllabelwidth}{\strut#1\strut}}
\newcommand{\CSLRightInline}[1]{\parbox[t]{\linewidth - \csllabelwidth}{\strut#1\strut}}
\newcommand{\CSLIndent}[1]{\hspace{\cslhangindent}#1}

\usepackage{fvextra}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{
    commandchars=\\\{\},
    breaklines, breaknonspaceingroup, breakanywhere
}
\KOMAoption{captions}{tableheading}
\makeatletter
\@ifpackageloaded{caption}{}{\usepackage{caption}}
\AtBeginDocument{%
\ifdefined\contentsname
  \renewcommand*\contentsname{Table of contents}
\else
  \newcommand\contentsname{Table of contents}
\fi
\ifdefined\listfigurename
  \renewcommand*\listfigurename{List of Figures}
\else
  \newcommand\listfigurename{List of Figures}
\fi
\ifdefined\listtablename
  \renewcommand*\listtablename{List of Tables}
\else
  \newcommand\listtablename{List of Tables}
\fi
\ifdefined\figurename
  \renewcommand*\figurename{Figure}
\else
  \newcommand\figurename{Figure}
\fi
\ifdefined\tablename
  \renewcommand*\tablename{Table}
\else
  \newcommand\tablename{Table}
\fi
}
\@ifpackageloaded{float}{}{\usepackage{float}}
\floatstyle{ruled}
\@ifundefined{c@chapter}{\newfloat{codelisting}{h}{lop}}{\newfloat{codelisting}{h}{lop}[chapter]}
\floatname{codelisting}{Listing}
\newcommand*\listoflistings{\listof{codelisting}{List of Listings}}
\makeatother
\makeatletter
\makeatother
\makeatletter
\@ifpackageloaded{caption}{}{\usepackage{caption}}
\@ifpackageloaded{subcaption}{}{\usepackage{subcaption}}
\makeatother

\usepackage{bookmark}

\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\urlstyle{same} % disable monospaced font for URLs
\hypersetup{
  pdftitle={Exploring Bot Detection on Reddit},
  pdfauthor={Matteo Mazzarelli},
  colorlinks=true,
  linkcolor={blue},
  filecolor={Maroon},
  citecolor={Blue},
  urlcolor={Blue},
  pdfcreator={LaTeX via pandoc}}


\title{Exploring Bot Detection on Reddit}
\usepackage{etoolbox}
\makeatletter
\providecommand{\subtitle}[1]{% add subtitle to \maketitle
  \apptocmd{\@title}{\par {\large #1 \par}}{}{}
}
\makeatother
\subtitle{Computational Social Science}
\author{Matteo Mazzarelli}
\date{March 24, 2025}

\begin{document}
\maketitle


\setstretch{1}
\section{Introduction}\label{introduction}

The pervasive presence of automated accounts, or bots, on social media
platforms has become a significant concern in the digital age. These
bots, designed to mimic human users, can manipulate online discussions,
disseminate misinformation, and potentially influence public opinion,
thus posing a threat to the integrity of online
communities\textsuperscript{{[}\citeproc{ref-botdetectionreddit}{1}{]}}.
Reddit, a platform structured around user-created communities known as
subreddits, is not immune to this issue. In fact, the platform's history
even includes the deliberate use of fake accounts to simulate activity
and attract genuine users, highlighting a long-standing awareness of the
impact of artificial
engagement\textsuperscript{{[}\citeproc{ref-redditbotproblem}{2}{]}}. As
bot technology becomes increasingly sophisticated, driven by
advancements in artificial intelligence, the need for effective
detection methods is more critical than
ever\textsuperscript{{[}\citeproc{ref-botdetectionreddit}{1}{]}}. This
paper investigates the detection of bots on Reddit, exploring the
efficacy of heuristic-based methods and the potential of large language
models (LLMs) to aid in this complex task.

The central research question guiding this study is: \textbf{Can basic
heuristic methods effectively identify bot influence on Reddit
discussions?}

This question is relevant for several reasons. Firstly, understanding
the extent of bot influence on Reddit is crucial for maintaining the
platform's credibility as a space for authentic discussion and
information sharing. Secondly, the development of effective bot
detection methods is essential to mitigate the potential negative
impacts of bots, such as the spread of misinformation and the
manipulation of public opinion. Finally, this research contributes to
the broader scholarly literature on social media bot detection by
focusing on Reddit, a platform with unique characteristics that may
require tailored detection strategies. Previous research has explored
various methods for bot detection on social media, often focusing on
platforms like
Twitter\textsuperscript{{[}\citeproc{ref-redditbotwatch}{3},\citeproc{ref-multibotdetector}{4}{]}}.
However, Reddit's community-driven structure and specific user behaviors
necessitate a dedicated investigation into bot detection within this
environment. This paper aims to contribute to this research gap by
evaluating the effectiveness of simple heuristic methods, readily
implementable and interpretable, in identifying bot influence on Reddit.
Furthermore, while exploring the potential of leveraging advanced LLMs
for keyword extraction and sentiment summarization to gain insights into
bot-driven narratives, it acknowledges that truly leveraging LLMs for
content-based bot detection would require a different approach, such as
labeling comment content for supervised learning. By combining
traditional heuristic methods with explorations into AI techniques, this
study aims to provide insights into both the practical applicability of
simpler approaches and the potential directions for more sophisticated
AI-driven solutions in the ongoing effort to detect and understand bot
activity on Reddit.

\section{Previous Predictive
Research}\label{previous-predictive-research}

The detection of bots on social media platforms is an area of increasing
scholarly attention, driven by the growing recognition of bots'
potential to manipulate online discourse and influence public
opinion\textsuperscript{{[}\citeproc{ref-multibotdetector}{4}{]}}.
Existing research in this field has primarily focused on platforms like
Twitter, examining a range of features and methodologies for identifying
automated
accounts\textsuperscript{{[}\citeproc{ref-redditbotwatch}{3}{]}}.

One prominent area of research involves the use of machine learning for
bot detection. Studies have explored various algorithms, including
tree-based classifiers like Random Forests and Decision Trees, as well
as more complex deep learning models such as Long Short-Term Memory
(LSTM)
networks\textsuperscript{{[}\citeproc{ref-multibotdetector}{4},\citeproc{ref-evalsocialbotmodels}{5}{]}}.
These approaches typically rely on a combination of features,
encompassing user metadata, activity patterns, and content
characteristics, to classify accounts as either bots or humans. For
instance, ensemble methods, which combine multiple classifiers, have
demonstrated promising results in multi-platform bot detection,
achieving notable accuracy
rates\textsuperscript{{[}\citeproc{ref-multibotdetector}{4},\citeproc{ref-multibotdetector}{4}{]}}.

Another significant research direction focuses on anomaly detection
techniques, which aim to identify accounts exhibiting behaviors that
deviate significantly from typical human user
patterns\textsuperscript{{[}\citeproc{ref-anomalycloudflare}{6},\citeproc{ref-anomalyf5networks}{7}{]}}.
These unsupervised learning methods are particularly valuable for
detecting novel bot behaviors that may not be captured by supervised
learning models trained on pre-labeled data. Histogram-Based Outlier
Scoring (HBOS) is one such algorithm that has been applied to scalable
anomaly detection in large datasets, demonstrating its potential for
identifying unusual activity patterns indicative of bot
behavior\textsuperscript{{[}\citeproc{ref-anomalycloudflare}{6}{]}}.

While a substantial body of research exists on bot detection in social
media, fewer studies have specifically focused on
Reddit\textsuperscript{{[}\citeproc{ref-botdetectionreddit}{1},\citeproc{ref-redditbotnetwork}{8},\citeproc{ref-mlredditbots}{9}{]}}.
Reddit's unique structure, characterized by topic-specific subreddits
and community-driven moderation, presents both distinct challenges and
opportunities for bot detection. Research focusing on Reddit has begun
to explore platform-specific features, such as user interaction networks
within subreddits, to identify bot
activity\textsuperscript{{[}\citeproc{ref-redditbotnetwork}{8}{]}}.
Furthermore, studies have investigated the role of bots in specific
contexts on Reddit, such as political discussions and the dissemination
of
misinformation\textsuperscript{{[}\citeproc{ref-botdetectionreddit}{1},\citeproc{ref-multibotdetector}{4}{]}}.

Publicly available datasets play a crucial role in advancing research in
this field. While datasets specifically labeled for Reddit bot detection
are less abundant compared to those for Twitter, resources like the
Pushshift Reddit
Dataset\textsuperscript{{[}\citeproc{ref-pushshiftredditdataset}{10}{]}}
and the Reddit Comments
Dataset\textsuperscript{{[}\citeproc{ref-redditcommentsdataset}{11}{]}}
offer valuable opportunities for researchers to collect and analyze
Reddit-specific
data\textsuperscript{{[}\citeproc{ref-multibotdetector}{4},\citeproc{ref-pushshiftredditdataset}{10},\citeproc{ref-redditcommentsdataset}{11}{]}}.
These datasets, while not always labeled for bot activity, provide rich
information on user comments, posts, and metadata that can be used to
develop and evaluate bot detection methods.

It is important to note that while existing research has explored
content-based features to some extent, truly leveraging the textual
content of comments for bot detection often requires labeled data where
human experts or advanced LLMs have categorized comments as originating
from bots or humans. This type of labeled data, specifically for Reddit
comment content, remains a relatively underexplored area, highlighting a
gap that future research could address.

In summary, previous predictive research on bot detection has
established a solid foundation of methodologies and features, primarily
focused on platforms like Twitter. However, the unique characteristics
of Reddit necessitate further investigation into tailored detection
strategies for this platform. This paper builds upon this existing
research by exploring the applicability of basic heuristic methods for
Reddit bot detection and by investigating the potential of LLMs for
keyword extraction and sentiment summarization as exploratory tools. It
also acknowledges the crucial next step of incorporating content-based
analysis, which would ideally involve labeled comment data, to move
beyond meta-metrics and enhance bot detection accuracy on Reddit. By
focusing on Reddit-specific data and combining heuristic approaches with
AI explorations, this study aims to contribute to the growing body of
knowledge on social media bot detection and address the specific
challenges posed by bot activity on Reddit.

\section{Data, Methods, and Models}\label{data-methods-and-models}

\subsection{Data}\label{data}

The data for this study was collected using the Reddit API via the
Python Reddit API Wrapper (PRAW). The collection period spanned March
23, 2025. The unit of analysis is individual Reddit comments.

\textbf{Subreddit Selection:} Subreddits were selected based on their
high subscriber counts and relevance to topics frequently targeted by
bots, such as politics and news. To ensure a reproducible and systematic
subreddit selection, keywords were generated using Google Gemini, a
large language model API. The prompt provided to Gemini requested
keywords associated with controversial topics likely to attract bot
activity. (See Appendix A.1 for the prompt and code used for keyword
generation). Based on these keywords and subscriber counts, a scoring
system was developed to rank subreddits by their potential vulnerability
to bot influence. (See Appendix A.2 for the scoring system and selected
subreddits). The top 10 subreddits according to this scoring system were
initially considered. For in-depth analysis and LLM querying, the top 5
subreddits with the highest bot influence scores were chosen:
r/worldnews, r/news, r/politics, r/science, and r/technology.

\textbf{Data Collection Procedure:} For each selected subreddit, the
Reddit API was used to collect posts and associated comments. The data
collected included:

\begin{itemize}
\tightlist
\item
  \textbf{Posts:} Post titles, post IDs, author usernames, subreddit
  names, submission types, timestamps of creation (UTC), and post text
  (selftext).
\item
  \textbf{Comments:} Comment IDs, author usernames, comment bodies,
  timestamps of creation (UTC), comment scores, comment levels (for
  nested comments), parent comment IDs, and post IDs.
\item
  \textbf{User Data:} For each comment author, publicly available user
  data such as account age (in days) and combined karma score (comment
  and link karma) were collected.
\end{itemize}

To manage data volume and processing time, the number of posts and
comments collected were limited. For each subreddit, the 50 hottest
posts were fetched, and for each post, a maximum of 2000 comments were
collected recursively, encompassing all comment levels. This
hierarchical approach aimed to capture a representative sample of
discussions within each subreddit while managing computational
resources.

\subsection{Measurement}\label{measurement}

\textbf{Bot Identification (Heuristics):} A heuristic-based bot
detection method was implemented, flagging accounts as potential bots if
they exhibited a combination of the following characteristics:

\begin{itemize}
\tightlist
\item
  \textbf{Young Account Age:} Accounts less than a year old were
  considered potentially bot-like.
\item
  \textbf{Unusual Karma:} Accounts with unusually low or high karma
  scores relative to their activity were flagged. Thresholds for
  ``unusual'' were empirically determined based on the data
  distribution.
\item
  \textbf{High Posting Frequency:} Accounts with exceptionally high
  posting frequency, particularly commenting in multiple subreddits
  within short time intervals, were considered suspicious.
\item
  \textbf{Repetitive Content:} Accounts frequently posting or commenting
  with highly similar or identical text were flagged for repetitive
  content. Cosine similarity of comment text was used to quantify
  content repetition.
\item
  \textbf{Em-dash Presence:} The presence of em-dashes (---) in comments
  was considered as a potential indicator of AI-generated content, as
  some AI models tend to overuse this punctuation
  mark\textsuperscript{{[}\citeproc{ref-redditbotdetector}{12}--\citeproc{ref-nightwateremdash}{14}{]}}.
\end{itemize}

These heuristics were chosen based on common bot characteristics
identified in previous research and community discussions on
Reddit\textsuperscript{{[}\citeproc{ref-redditbotslearnusetalents}{15}--\citeproc{ref-botproblem7daystodie}{17}{]}},
and incorporating recent observations about AI-generated text
markers\textsuperscript{{[}\citeproc{ref-redditbotdetector}{12}--\citeproc{ref-nightwateremdash}{14}{]}}.
A ``Bot Score'' was calculated for each account based on the number of
heuristics triggered. Accounts exceeding a certain threshold on the
``Bot Score'' were classified as ``possible bots'' or ``very likely
bots,'' allowing for varying degrees of bot likelihood assessment. (See
code for precise implementation of heuristic thresholds and scoring). It
is important to note that these heuristics primarily rely on
meta-metrics and basic content features like punctuation, and do not
deeply analyze the semantic content of the comments themselves.

\textbf{Narrative Amplification:} Narrative amplification was measured
by analyzing the frequency of keywords associated with potentially
bot-driven narratives within subreddit discussions. Keywords related to
bot-influenced topics (e.g., politics, controversial issues) were
generated using Google Gemini (see Appendix A.1). The frequency of these
keywords in comments from accounts flagged as potential bots was
compared to their frequency in comments from non-flagged accounts to
assess potential narrative amplification.

\textbf{Polarization:} Polarization was assessed using sentiment
analysis of comment content. The VADER (Valence Aware Dictionary and
sEntiment Reasoner) sentiment analysis tool was employed to calculate
compound sentiment scores for comments. Average sentiment scores were
compared between comments from accounts flagged as potential bots and
those from non-flagged accounts to identify potential differences in
sentiment polarity, which could indicate bot-driven polarization.

\subsection{Models}\label{models}

\textbf{Heuristic Bot Detection Model:} The core model employed in this
study is a heuristic-based bot detection system. This model does not
rely on traditional machine learning classification but instead uses a
set of predefined rules (heuristics) based on observable account
characteristics to identify potential bots. The specific heuristics and
their implementation are detailed in the ``Measurement'' section above
and in the provided code.

\textbf{Large Language Model (LLM) for Keyword Extraction and Sentiment
Summarization:} Google Gemini, a state-of-the-art LLM, was utilized to
extract keywords and generate sentiment summaries for comments within
each of the top 5 subreddits. The \texttt{generate} function, configured
for deterministic output (temperature=0, top\_p=0, top\_k=1), was used
to query Gemini. The prompt provided to Gemini requested:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \textbf{Keyword Extraction:} Identification of 20 unique keywords
  capturing the essence of each subreddit's discussions, based
  exclusively on a sample of comments.
\item
  \textbf{Sentiment Summary:} A brief summary of the overall sentiment
  expressed in the comments, indicating whether the tone was positive,
  negative, or neutral.
\end{enumerate}

The LLM's output was then parsed to extract the keyword list and
sentiment summary for each subreddit. Word clouds were generated from
the extracted keywords to visually represent the dominant themes within
each subreddit's discussions. It's important to note that while LLMs are
used here for analysis, they are not directly integrated into the
heuristic bot detection model itself, and their role is primarily
exploratory in this study.

\textbf{Evaluation of Bot Detection Effectiveness:} The effectiveness of
the heuristic-based bot detection method was evaluated both
qualitatively and quantitatively.

\begin{itemize}
\item
  \textbf{Qualitative Evaluation:} A manual review of accounts flagged
  as potential bots was conducted to assess the face validity of the
  heuristics and examine the characteristics of flagged accounts.
  Subreddit-specific word clouds generated from LLM keyword extraction
  were analyzed to understand the thematic focus of discussions and
  potentially identify bot-driven narratives. Sentiment summaries
  provided by the LLM were evaluated for their coherence and consistency
  with the overall tone of subreddit discussions.
\item
  \textbf{Quantitative Evaluation (Exploratory):} To explore the
  potential for quantitative evaluation, simple classification models
  (Random Forest, SVM, Neural Network) were trained using features
  derived from the heuristic analysis (Bot Score, account age, karma,
  posting frequency, content repetitiveness, em-dash presence, etc.).
  The performance of these models was assessed using standard
  classification metrics (accuracy, precision, recall, F1-score,
  confusion matrices) and cross-validation. This quantitative evaluation
  was exploratory, given the lack of a true ``ground truth'' dataset for
  bot identification in this study and the limitation of relying solely
  on meta-metrics and basic content features without labeled content
  data. It aimed to provide a preliminary indication of the
  heuristic-based approach's predictive capability and guide future
  research directions involving more rigorous machine learning
  evaluation that incorporates content-based features from labeled data.
\end{itemize}

\subsection{Reproducibility}\label{reproducibility}

To ensure the reproducibility of this research, all code used for data
collection, analysis, and model implementation is provided in the
supplementary materials (``Surname\_Firstname\_code.R'' and
``Surname\_Firstname\_code.do''). The code includes:

\begin{itemize}
\tightlist
\item
  \textbf{Data Collection Scripts:} Python scripts using PRAW to access
  the Reddit API and collect posts, comments, and user data.
\item
  \textbf{Heuristic Bot Detection Implementation:} Code implementing the
  heuristic-based bot detection rules and Bot Score calculation,
  including em-dash detection.
\item
  \textbf{LLM Querying and Keyword Extraction:} Python code using the
  Google Gemini API to query the LLM for keyword extraction and
  sentiment summaries.
\item
  \textbf{Data Analysis and Visualization Scripts:} R and Python scripts
  for data processing, statistical analysis, sentiment analysis, word
  cloud generation, and exploratory machine learning model training and
  evaluation.
\end{itemize}

The ``Surname(s).zip'' folder also contains a ``data.csv'' file, which
is a sample of the raw data collected from Reddit. Due to the constantly
evolving nature of Reddit data and API access, the provided code may
require minor adjustments to be executed perfectly ``out of the box'' at
a future date. However, the code is designed to be as self-contained and
well-commented as possible to facilitate replication by other
researchers. The stochastic elements of LLM output are minimized by
setting temperature and sampling parameters to ensure reproducible
keyword generation.

\section{Empirical Results}\label{empirical-results}

\subsection{Descriptive Analysis of Bot
Characteristics}\label{descriptive-analysis-of-bot-characteristics}

The heuristic-based bot detection method identified a subset of Reddit
accounts exhibiting characteristics consistent with bot-like behavior.
Descriptive analysis of these flagged accounts revealed several key
patterns:

\begin{itemize}
\item
  \textbf{Username Patterns:} A significant proportion of flagged
  accounts displayed usernames composed of random strings of letters and
  numbers or followed patterns associated with bot accounts, such as
  default Reddit-generated usernames.
\item
  \textbf{Account Age:} Flagged accounts tended to be younger on average
  compared to non-flagged accounts, with a notable concentration of
  accounts less than a year old.
\item
  \textbf{Karma Distribution:} The karma scores of flagged accounts
  showed a bimodal distribution, with some accounts exhibiting very low
  karma and others surprisingly high karma. The high-karma bot accounts
  appeared to be ``karma-farming'' bots, designed to accumulate karma to
  appear more legitimate.
\item
  \textbf{Posting Frequency:} Flagged accounts exhibited significantly
  higher posting frequencies compared to non-flagged accounts. Some
  accounts posted comments in multiple subreddits within extremely short
  time intervals, indicative of automated posting behavior.
\item
  \textbf{Content Repetitiveness:} Analysis of comment content revealed
  a higher degree of text similarity and repetition among flagged
  accounts. Many flagged accounts posted generic, short comments that
  were often contextually irrelevant or repeated across different
  threads.
\item
  \textbf{Em-dash Usage:} Flagged accounts showed a slightly higher
  prevalence of em-dash usage in their comments compared to non-flagged
  accounts, although this difference was not statistically significant
  in this analysis.
\end{itemize}

\subsection{Cross-Subreddit Content Similarity and Narrative
Amplification}\label{cross-subreddit-content-similarity-and-narrative-amplification}

To understand the relationships between the top subreddits in terms of
content, and to explore potential narrative amplification, a
cross-subreddit content similarity analysis was conducted. Figure 1
displays a heatmap visualizing the cosine similarity of TF-IDF vectors
generated from the combined text of comments within each of the top 5
subreddits.

\textbf{Figure 1: Cross-Subreddit Content Similarity Heatmap}

\emph{(Figure 1: Cross-Subreddit Content Similarity Heatmap is inserted
here - See Appendix B, Figure 9 in the original notebook)}

\emph{Note: The heatmap visualizes the cosine similarity of TF-IDF
vectors between the top 5 subreddits, with darker colors indicating
higher similarity and lighter colors indicating lower similarity.}

As shown in Figure 1, the heatmap reveals moderate content similarity
between certain subreddits. \texttt{r/news} and \texttt{r/worldnews}
exhibit the highest content similarity (0.81), which is expected given
their overlapping topical focus on current events. \texttt{r/politics}
also shows relatively high similarity with \texttt{r/news} (0.80) and
\texttt{r/worldnews} (0.72), indicating thematic connections between
political discussions and news reporting. \texttt{r/technology} and
\texttt{r/science} show lower similarity with the news and politics
subreddits, reflecting their distinct subject matter. \texttt{r/science}
and \texttt{r/technology} exhibit moderate similarity to each other
(0.63). This suggests a thematic clustering where news and politics
subreddits are more closely related in content, while technology and
science form a separate, though somewhat related, cluster. Bots
operating across these subreddits might exploit these thematic
connections to amplify narratives across related communities.

Analysis of keyword frequencies and sentiment scores provided further
insights into potential narrative amplification and polarization
associated with flagged accounts.

\begin{itemize}
\tightlist
\item
  \textbf{Keyword Analysis:} Figure 2 shows the word cloud generated by
  Google Gemini for the r/politics subreddit. Keywords like
  ``government,'' ``election,'' ``Democrats,'' and ``Trump'' are
  prominently featured, reflecting the politically charged nature of
  discussions in this subreddit. Keywords generated by Google Gemini for
  subreddits like r/politics and r/worldnews, which are known to be
  prone to bot activity, were frequently observed in comments from
  flagged accounts. These keywords often related to politically charged
  topics, conspiracy theories, and divisive narratives. While flagged
  accounts exhibited a numerically higher frequency of these
  bot-influence keywords compared to non-flagged accounts, the
  difference was not statistically significant in this analysis. This
  suggests that, based solely on keyword frequency, bots and humans in
  these subreddits may not differ substantially in their topical focus
  when analyzed with simple methods.
\end{itemize}

\textbf{Figure 2: Word Cloud for /r/politics}

\emph{(Figure 2: Word Cloud for /r/politics is inserted here - See
Appendix B, Figure 1 in the original notebook)}

\begin{itemize}
\tightlist
\item
  \textbf{Sentiment Analysis:} Sentiment analysis using VADER revealed
  subtle differences in the average sentiment polarity of comments from
  flagged and non-flagged accounts. While both groups exhibited a
  generally negative sentiment, comments from flagged accounts showed a
  slightly more pronounced negative sentiment on average, particularly
  in politically polarized subreddits. However, similar to keyword
  analysis, this difference in average sentiment was not statistically
  significant. This indicates that, based on sentiment scores alone,
  distinguishing between bot and human comments remains challenging with
  basic sentiment analysis tools, suggesting bots may be capable of
  mimicking human sentiment expression to some extent.
\end{itemize}

The lack of statistically significant differences in keyword frequencies
and sentiment scores between flagged and non-flagged accounts suggests
that, when relying solely on these metrics, bots may be increasingly
adept at mimicking human language patterns, at least at a surface level
of topic and sentiment. This underscores the limitation of relying
solely on simple content analysis or meta-metrics for bot detection and
points to the need for more nuanced approaches that consider the deeper
semantic and contextual aspects of comment content, potentially through
human or advanced LLM-based content labeling.

\subsection{Exploratory Quantitative Evaluation of Bot
Detection}\label{exploratory-quantitative-evaluation-of-bot-detection}

Exploratory quantitative evaluation using simple machine learning
classifiers provided a preliminary assessment of the heuristic-based bot
detection approach.

\begin{itemize}
\item
  \textbf{Classification Model Performance:} Random Forest, SVM, and
  Neural Network classifiers were trained to distinguish between flagged
  and non-flagged accounts using the heuristic-derived features. The
  Random Forest classifier achieved the highest performance, with an
  accuracy of approximately 75\% in cross-validation. SVM and Neural
  Network models showed slightly lower accuracy rates (around 70\% and
  68\%, respectively).
\item
  \textbf{Feature Importance:} Feature importance analysis from the
  Random Forest model indicated that posting frequency and content
  repetitiveness were the most influential features in distinguishing
  between flagged and non-flagged accounts. Account age, karma score,
  and em-dash presence also contributed to the model's predictive
  capability, albeit to a lesser extent. This reinforces the idea that
  behavioral patterns, captured by meta-metrics like posting frequency
  and content repetition, are more indicative of bot activity than
  simple content analysis of keywords or sentiment in this heuristic
  approach.
\item
  \textbf{Confusion Matrices:} Figure 3 shows the confusion matrix for
  the Random Forest classifier, which achieved the best performance
  among the tested models. The model exhibited a tendency to misclassify
  some non-bot accounts as bots (false positives), while achieving
  relatively better performance in correctly identifying flagged
  accounts (true positives). This suggests that the heuristic-based
  approach, while effective in identifying some bot-like accounts based
  on meta-metrics, may also inadvertently flag some legitimate, highly
  active users.
\end{itemize}

\textbf{Figure 3: Confusion Matrix for Random Forest Classifier}

\emph{(Figure 3: Confusion Matrix for Random Forest Classifier is
inserted here - See Appendix B, Figure 6 in the original notebook)}

These quantitative results are preliminary and should be interpreted
cautiously due to the lack of a true ground truth dataset and the
limitations of relying solely on meta-metrics and basic content
features. However, they provide initial evidence supporting the
heuristic-based approach's potential for bot detection on Reddit and
highlight areas for future refinement, particularly in reducing false
positives and incorporating more sophisticated content-based features
derived from labeled data.

\section{Discussion and Conclusion}\label{discussion-and-conclusion}

This study explored the feasibility of using basic heuristic methods for
detecting bot influence on Reddit discussions. The findings suggest that
simple heuristics, based on readily observable account characteristics
such as username patterns, account age, karma, posting frequency,
content repetitiveness, and em-dash presence, can effectively identify a
subset of accounts exhibiting bot-like behavior based on meta-metrics.
Descriptive analysis of flagged accounts revealed patterns consistent
with known bot characteristics, and exploratory quantitative evaluation
using machine learning classifiers provided preliminary support for the
predictive capability of the heuristic-based approach when relying on
these meta-metrics and basic content features.

However, and importantly, the analysis of keyword frequencies and
sentiment scores did \textbf{not} reveal statistically significant
differences between flagged and non-flagged accounts. This key finding
suggests that, while heuristic methods based on meta-metrics can
identify certain bot-like accounts, these bots may be increasingly
sophisticated in mimicking human language in terms of topical focus and
sentiment expression, at least when analyzed using simple keyword
frequency and sentiment analysis tools. This highlights a crucial
limitation of relying solely on meta-metrics and basic content analysis
for bot detection in the face of increasingly advanced automated
accounts. \textbf{It also suggests that simply analyzing keyword
frequencies or overall sentiment polarity may not be sufficient to
distinguish bots from humans in terms of content, and more nuanced,
context-aware content analysis methods are needed.}

The study also investigated potential narrative amplification and
polarization associated with flagged accounts. While suggestive evidence
of narrative amplification was observed through keyword analysis, and
subtle differences in sentiment polarity were detected, the lack of
statistical significance in these content-based analyses underscores the
challenges in definitively attributing these phenomena to bot activity
based on the methods employed here. LLM-generated word clouds, while
thematically informative in visualizing subreddit topics, similarly did
not provide clear differentiation between bot and human language use in
terms of content.

\textbf{In essence, the study demonstrates that while basic heuristics
can flag accounts exhibiting bot-like \emph{behavior}, these heuristics
alone are insufficient to definitively identify bots or understand their
influence on \emph{content} without more advanced content-based analysis
methods and labeled data.}

\subsection{Limitations}\label{limitations}

This study has several limitations that should be considered when
interpreting the findings:

\begin{itemize}
\item
  \textbf{Heuristic Accuracy and Reliance on Meta-metrics:} The
  heuristic-based bot detection method, while interpretable and readily
  implementable, is inherently limited in its accuracy, particularly
  when relying solely on meta-metrics. It relies on predefined rules
  that may not capture the full spectrum of bot behaviors, especially
  increasingly sophisticated bots that closely mimic human users and
  whose content may be indistinguishable from human content when
  analyzed with basic
  methods\textsuperscript{{[}\citeproc{ref-botdetectionreddit}{1}{]}}.
  The exploratory quantitative evaluation revealed a tendency for false
  positives, indicating that the heuristics may inadvertently flag some
  legitimate users as bots. Crucially, the lack of significant
  differences in keyword frequencies and sentiment scores suggests that
  \textbf{meta-metrics alone are insufficient for a comprehensive and
  nuanced understanding of bot activity, and that content-based analysis
  is essential for future progress.}
\item
  \textbf{Lack of Ground Truth and Content Labeling:} The absence of a
  true ``ground truth'' dataset for bot identification on Reddit poses a
  significant challenge for rigorous quantitative evaluation. Moreover,
  the study \textbf{did not incorporate a crucial element for
  content-based bot detection: labeled data where comment bodies are
  categorized as bot-generated or human-generated.} The exploratory
  machine learning evaluation provides only a preliminary indication of
  the heuristic approach's predictive capability based on meta-metrics
  but cannot definitively assess its accuracy against a verified
  bot/human classification that incorporates content analysis.
  \textbf{Future research must prioritize the creation of such labeled
  datasets, potentially through human annotation or LLM-assisted
  labeling, to enable the development of more robust content-aware bot
  detection models.}
\item
  \textbf{Data Sampling:} The data collection was limited to the top 50
  hottest posts per subreddit and a maximum of 2000 comments per post.
  This sampling approach may not capture the full diversity of
  discussions and bot activity across Reddit. Furthermore, the analysis
  focused on only the top 5 subreddits, limiting the generalizability of
  the findings to the entire Reddit platform.
\item
  \textbf{LLM Dependency for Exploratory Analysis:} The study's reliance
  on Google Gemini for keyword extraction and sentiment summarization,
  while providing exploratory insights, introduces a dependency on a
  specific LLM API and is not a substitute for direct content-based bot
  detection. While efforts were made to ensure reproducibility by tuning
  LLM parameters, the results should be seen as qualitative explorations
  rather than definitive quantitative measures of bot influence on
  content.
\end{itemize}

\subsection{Future Research
Directions}\label{future-research-directions}

Future research should address these limitations and further explore the
detection of bots on Reddit, with a particular emphasis on moving beyond
meta-metrics and incorporating content-based analysis:

\begin{itemize}
\item
  \textbf{Refinement of Heuristics and Integration of Content Features:}
  Further research is needed to refine and expand the heuristic-based
  bot detection method, \textbf{integrating content-based features
  derived from labeled data.} This could involve incorporating more
  sophisticated meta-metrics, such as network-based metrics derived from
  user interaction patterns within subreddits, \textbf{but crucially, it
  should also prioritize features extracted directly from the comment
  text itself, leveraging human-validated labeled data to identify
  nuanced linguistic patterns indicative of bot-generated content, going
  beyond simple metrics like em-dash presence to encompass stylistic
  features, semantic coherence, contextual relevance, and even subtle
  cues in argumentation and conversational style.} Adaptive heuristics
  that dynamically adjust to evolving bot behaviors, \textbf{including
  content generation strategies}, could also be explored.
\item
  \textbf{Development of Ground Truth Datasets with Human-Validated
  Content Labels:} A critical step for future research is the
  development of high-quality, labeled datasets for Reddit bot detection
  \textbf{that include human-validated labels for comment content.} This
  could involve combining manual labeling by expert Reddit moderators
  with \textbf{LLM-assisted labeling techniques to categorize comment
  bodies as bot or human-generated, with a rigorous human review and
  validation process to ensure label accuracy and minimize biases.} This
  labeled data is essential to train and evaluate models that can
  effectively leverage content-based features for bot detection, moving
  beyond the limitations of meta-metrics and basic content features.
\item
  \textbf{Advanced Machine Learning Models for Content-Aware Bot
  Detection:} Future studies should investigate the application of more
  advanced machine learning models, including deep learning
  architectures and graph neural networks, \textbf{trained on datasets
  with human-validated content labels}, for Reddit bot detection. These
  models, capable of processing and understanding natural language, may
  be better suited to capture the complex behavioral and linguistic
  patterns of sophisticated bots and potentially improve detection
  accuracy \textbf{by learning directly from the content of bot and
  human comments, going beyond simple keyword or sentiment analysis to
  understand deeper semantic, stylistic, and contextual cues that
  differentiate human and bot-generated text.}
\item
  \textbf{Hybrid Approaches Combining Meta-metrics and Content
  Analysis:} Combining heuristic-based methods, focused on meta-metrics,
  with machine learning models trained on content-labeled data could
  offer a promising avenue for future research. Heuristics could be used
  for initial feature engineering and data pre-processing of meta-data,
  while machine learning models could be trained to learn more complex
  patterns and improve detection accuracy \textbf{by incorporating both
  meta-metric and content-based features derived from human-validated
  labeled data, creating a more robust and nuanced bot detection system
  that leverages the strengths of both rule-based and data-driven
  approaches.}
\item
  \textbf{Real-time Bot Detection Systems with Content Analysis
  Capabilities and Ethical Considerations:} Developing real-time bot
  detection systems that can proactively identify and flag malicious
  activity on Reddit is a crucial direction for future work. This would
  require efficient and scalable algorithms capable of processing large
  volumes of streaming Reddit data and \textbf{incorporating
  sophisticated content analysis in real-time, potentially through
  optimized and ethically vetted LLM-based feature extraction or
  lightweight content classification models, while also carefully
  addressing the computational cost, latency considerations, and ethical
  implications of real-time content processing and automated bot
  flagging.} \textbf{Ethical considerations, particularly regarding
  potential biases in content labels and algorithmic detection, and the
  need for transparency and user recourse mechanisms in content-based
  bot detection systems, must be central to future development.}
\end{itemize}

\subsection{Conclusion}\label{conclusion}

This study provides a preliminary exploration into the detection of bots
on Reddit using basic heuristic methods and LLMs for exploratory
analysis. While heuristic-based approaches offer a readily implementable
and interpretable starting point for identifying some bot-like accounts
based on meta-metrics, the study highlights the crucial limitation of
relying solely on meta-metrics and basic content analysis in the face of
increasingly sophisticated bots. \textbf{The key takeaway is the
necessity of moving beyond meta-metrics and incorporating
human-validated content-based analysis, which requires the development
of labeled datasets and the application of advanced machine learning
models capable of understanding and learning from the textual content of
Reddit comments, while carefully considering ethical implications and
ensuring fairness and transparency.} Future research must prioritize
these directions to develop more robust, accurate, ethically sound, and
content-aware bot detection systems for this complex and evolving online
environment. The ongoing effort to detect and mitigate bot influence,
particularly through advanced content-aware methods, is crucial for
maintaining the integrity and trustworthiness of online social platforms
and ensuring a healthy digital public sphere.

\subsection{References}\label{references}

\phantomsection\label{refs}
\begin{CSLReferences}{1}{0}
\bibitem[\citeproctext]{ref-botdetectionreddit}
1. Hurtado S., Ray P., \& Marculescu R. (2019). Bot detection in reddit
political discussion. \emph{ResearchGate}.
\url{https://www.researchgate.net/publication/332340547_Bot_Detection_in_Reddit_Political_Discussion}

\bibitem[\citeproctext]{ref-redditbotproblem}
2. Dawson A. (2024). Does reddit have a bot problem? absolutely. In
\emph{Lunio}. \url{https://www.lunio.ai/blog/reddit-bots}

\bibitem[\citeproctext]{ref-redditbotwatch}
3. R/botwatch. (2022). In \emph{Reddit}.
\url{https://www.reddit.com/r/botwatch/}

\bibitem[\citeproctext]{ref-multibotdetector}
4. Ng L. H. X., \& Carley K. M. (2022). Assembling a multi-platform
ensemble social bot detector with applications to US 2020 elections.
\emph{arXiv}. \url{https://arxiv.org/html/2401.14607v1}

\bibitem[\citeproctext]{ref-evalsocialbotmodels}
5. Kutlu M., \& SelÃ§uk A. A. (2025). Evaluation of social bot detection
models. \emph{ResearchGate}.
\url{https://www.researchgate.net/publication/361038547_Evaluation_of_social_bot_detection_models}

\bibitem[\citeproctext]{ref-anomalycloudflare}
6. Tang J. (2024). \emph{Lessons learned from scaling up cloudflare's
anomaly detection platform}.
\url{https://blog.cloudflare.com/lessons-learned-from-scaling-up-cloudflare-anomaly-detection-platform/}

\bibitem[\citeproctext]{ref-anomalyf5networks}
7. Tang J. (2024). How does anomaly detection work? : R/f5networks. In
\emph{Reddit}.
\url{https://www.reddit.com/r/f5networks/comments/13jw4qg/how_does_anomaly_detection_work/}

\bibitem[\citeproctext]{ref-redditbotnetwork}
8. Damasceno R. (2019). Identify-bots-reddit-comment-network:
Characterization and classification of bots using only structural
characteristics of the network. In \emph{GitHub}.
\url{https://github.com/DamascenoRafael/identify-bots-reddit-comment-network}

\bibitem[\citeproctext]{ref-mlredditbots}
9. Skowronski J. (2019). Identifying trolls and bots on reddit with
machine learning. In \emph{Medium}.
\url{https://medium.com/towards-data-science/identifying-trolls-and-bots-on-reddit-with-machine-learning-709da5970af1}

\bibitem[\citeproctext]{ref-pushshiftredditdataset}
10. Baumgartner J., Zannettou S., Keegan B., Squire M., \& Blackburn J.
(2020). The pushshift reddit dataset. \emph{AAAI Publications}.
\url{https://ojs.aaai.org/index.php/ICWSM/article/view/7347/7201}

\bibitem[\citeproctext]{ref-redditcommentsdataset}
11. Tkachenko V. (2021). Reddit comments dataset. In \emph{ClickHouse
Docs}.
\url{https://clickhouse.com/docs/getting-started/example-datasets/reddit-comments}

\bibitem[\citeproctext]{ref-redditbotdetector}
12. Tourond M. (2019). Reddit-bot-detector: A python bot that detects
reddit bots. In \emph{GitHub}.
\url{https://github.com/MatthewTourond/Reddit-Bot-Detector}

\bibitem[\citeproctext]{ref-originalityaiblog}
13. Gillham J., \& Lambert M. (2023). \emph{Are you getting advice from
a human or bot? Reddit shows spikes in AI content}.
\url{https://originality.ai/blog/reddit-shows-spikes-in-ai-content}

\bibitem[\citeproctext]{ref-nightwateremdash}
14. Bush C. (2023). \emph{The em dash and AI: A conjunction - night
water}. \url{https://www.nightwater.email/em-dash-ai/}

\bibitem[\citeproctext]{ref-redditbotslearnusetalents}
15. How to identify bots on reddit : R/LearnUselessTalents. (2023). In
\emph{Reddit}.
\url{https://www.reddit.com/r/LearnUselessTalents/comments/15tzjkb/how_to_identify_bots_on_reddit/}

\bibitem[\citeproctext]{ref-botsidentifytyrannosnorlax}
16. u/tyrannosnorlax. (2022). Bots. How to identify them, and why do
they exist on reddit? In \emph{Reddit}.
\url{https://www.reddit.com/user/tyrannosnorlax/comments/t0h466/bots_how_to_identify_them_and_why_do_they_exist/}

\bibitem[\citeproctext]{ref-botproblem7daystodie}
17. Bot problem - how to identify bot accounts (99\% accuracy) :
R/7daystodie. (2025). In \emph{Reddit}.
\url{https://www.reddit.com/r/7daystodie/comments/1au1g1s/bot_problem_how_to_identify_bot_accounts_99/}

\end{CSLReferences}

\subsection{\texorpdfstring{\textbf{Appendices}}{Appendices}}\label{appendices}

\textbf{Appendix A: Keyword Generation and Subreddit Selection Details}

\textbf{A.1 Keyword Generation Code and Prompt}

\emph{(See Appendix A.1 in the original notebook for code and prompt)}

\textbf{A.2 Selected Subreddits and Scoring System}

\emph{(See Appendix A.2 in the original notebook for selected subreddits
table and scoring system description)}

\textbf{Appendix B: Figures and Tables}

\textbf{Figure 1: Word Cloud for /r/politics} \emph{(See Appendix B,
Figure 1 in the original notebook)}

\textbf{Figure 2: Word Cloud for /r/worldnews} \emph{(See Appendix B,
Figure 2 in the original notebook)}

\textbf{Figure 3: Word Cloud for /r/news} \emph{(See Appendix B, Figure
3 in the original notebook)}

\textbf{Figure 4: Word Cloud for /r/technology} \emph{(See Appendix B,
Figure 4 in the original notebook)}

\textbf{Figure 5: Word Cloud for /r/science} \emph{(See Appendix B,
Figure 5 in the original notebook)}

\textbf{Figure 6: Confusion Matrix for SVM Classifier} \emph{(See
Appendix B, Figure 7 in the original notebook)}

\textbf{Figure 7: Confusion Matrix for Neural Network Classifier}
\emph{(See Appendix B, Figure 8 in the original notebook)}




\end{document}
