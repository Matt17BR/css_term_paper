{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install praw\n",
    "# %pip install google-generativeai\n",
    "# %pip install ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.generativeai as genai\n",
    "import os\n",
    "\n",
    "genai.configure(api_key=os.environ[\"GEMINI_API_KEY\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Subscribers</th>\n",
       "      <th>Description</th>\n",
       "      <th>Over 18</th>\n",
       "      <th>Submission Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>funny</td>\n",
       "      <td>65904846</td>\n",
       "      <td>Reddit's largest humor depository</td>\n",
       "      <td>False</td>\n",
       "      <td>any</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AskReddit</td>\n",
       "      <td>50382485</td>\n",
       "      <td>r/AskReddit is the place to ask and answer tho...</td>\n",
       "      <td>False</td>\n",
       "      <td>self</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gaming</td>\n",
       "      <td>44948179</td>\n",
       "      <td>The Number One Gaming forum on the Internet.</td>\n",
       "      <td>False</td>\n",
       "      <td>any</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>worldnews</td>\n",
       "      <td>43556495</td>\n",
       "      <td>A place for major news from around the world, ...</td>\n",
       "      <td>False</td>\n",
       "      <td>link</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>todayilearned</td>\n",
       "      <td>39198977</td>\n",
       "      <td>You learn something new every day; what did yo...</td>\n",
       "      <td>False</td>\n",
       "      <td>link</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>aww</td>\n",
       "      <td>37356069</td>\n",
       "      <td>Things that make you go AWW! -- like puppies, ...</td>\n",
       "      <td>False</td>\n",
       "      <td>link</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Music</td>\n",
       "      <td>35809226</td>\n",
       "      <td>Reddit’s #1 Music Community</td>\n",
       "      <td>False</td>\n",
       "      <td>any</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>memes</td>\n",
       "      <td>35215501</td>\n",
       "      <td>Memes!\\n\\nA way of describing cultural informa...</td>\n",
       "      <td>False</td>\n",
       "      <td>any</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>movies</td>\n",
       "      <td>34166418</td>\n",
       "      <td>The goal of /r/Movies is to provide an inclusi...</td>\n",
       "      <td>False</td>\n",
       "      <td>any</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Showerthoughts</td>\n",
       "      <td>33638524</td>\n",
       "      <td>A subreddit for sharing those miniature epipha...</td>\n",
       "      <td>False</td>\n",
       "      <td>self</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Name  Subscribers  \\\n",
       "0           funny     65904846   \n",
       "1       AskReddit     50382485   \n",
       "2          gaming     44948179   \n",
       "3       worldnews     43556495   \n",
       "4   todayilearned     39198977   \n",
       "5             aww     37356069   \n",
       "6           Music     35809226   \n",
       "7           memes     35215501   \n",
       "8          movies     34166418   \n",
       "9  Showerthoughts     33638524   \n",
       "\n",
       "                                         Description  Over 18 Submission Type  \n",
       "0                  Reddit's largest humor depository    False             any  \n",
       "1  r/AskReddit is the place to ask and answer tho...    False            self  \n",
       "2       The Number One Gaming forum on the Internet.    False             any  \n",
       "3  A place for major news from around the world, ...    False            link  \n",
       "4  You learn something new every day; what did yo...    False            link  \n",
       "5  Things that make you go AWW! -- like puppies, ...    False            link  \n",
       "6                        Reddit’s #1 Music Community    False             any  \n",
       "7  Memes!\\n\\nA way of describing cultural informa...    False             any  \n",
       "8  The goal of /r/Movies is to provide an inclusi...    False             any  \n",
       "9  A subreddit for sharing those miniature epipha...    False            self  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import praw\n",
    "import pandas as pd\n",
    "\n",
    "# Replace with your actual credentials\n",
    "reddit = praw.Reddit(\n",
    "    client_id=os.environ[\"PRAW_CLIENT_ID\"],\n",
    "    client_secret=os.environ[\"PRAW_CLIENT_SECRET\"],\n",
    "    user_agent=os.environ[\"PRAW_USER_AGENT\"],\n",
    "    username=os.environ[\"PRAW_USERNAME\"],\n",
    "    password=os.environ[\"PRAW_PASSWORD\"],\n",
    ")\n",
    "\n",
    "# Fetch a large subset of popular subreddits (large limit makes this representative of the largest overall subreddits by subscribers, check: https://gummysearch.com/tools/top-subreddits/)\n",
    "subreddits = list(reddit.subreddits.popular(limit=1000))\n",
    "\n",
    "# Create a DataFrame using list comprehension for better performance\n",
    "subs_df = pd.DataFrame([{\n",
    "    \"Name\": subreddit.display_name,\n",
    "    \"Subscribers\": subreddit.subscribers,\n",
    "    \"Description\": subreddit.public_description,\n",
    "    \"Over 18\": subreddit.over18,\n",
    "    \"Submission Type\": subreddit.submission_type\n",
    "} for subreddit in subreddits]).sort_values(by=\"Subscribers\", ascending=False, ignore_index=True)\n",
    "\n",
    "# Print the top 10\n",
    "subs_df.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 subreddits potentially vulnerable to bot influence:\n",
      "              Name  Subscribers Submission Type  bot_score\n",
      "10         science     33418689            link          5\n",
      "31   UpliftingNews     20188675            link          5\n",
      "103       AskWomen      5548640            self          5\n",
      "1        AskReddit     50382485            self          4\n",
      "3        worldnews     43556495            link          4\n",
      "5              aww     37356069            link          4\n",
      "12           Jokes     30343746            self          4\n",
      "13            news     29220252            link          4\n",
      "26             Art     22367812            link          4\n",
      "27          sports     21706259            link          4\n"
     ]
    }
   ],
   "source": [
    "# Create a list of keywords that might indicate bot influence potential\n",
    "bot_influence_keywords = ['news', 'memes', 'discussion', 'questions', 'share', 'post', 'community']\n",
    "\n",
    "# Score subreddits based on subscribers and keywords in description\n",
    "def calculate_bot_influence_score(row):\n",
    "    score = 0\n",
    "    \n",
    "    # Large subscriber base increases potential for bot activity\n",
    "    if row['Subscribers'] > 10000000:\n",
    "        score += 3\n",
    "    elif row['Subscribers'] > 5000000:\n",
    "        score += 2\n",
    "    elif row['Subscribers'] > 1000000:\n",
    "        score += 1\n",
    "        \n",
    "    # Check for keywords in description\n",
    "    description = row['Description'].lower()\n",
    "    for keyword in bot_influence_keywords:\n",
    "        if keyword in description:\n",
    "            score += 1\n",
    "            \n",
    "    return score\n",
    "\n",
    "# Filter for link/self submissions and calculate scores\n",
    "bot_vulnerable_subs = subs_df[\n",
    "    (subs_df['Submission Type'].isin(['link', 'self']))\n",
    "].copy()\n",
    "\n",
    "bot_vulnerable_subs['bot_score'] = bot_vulnerable_subs.apply(calculate_bot_influence_score, axis=1)\n",
    "\n",
    "# Get top 10 most vulnerable subreddits\n",
    "top_vulnerable = bot_vulnerable_subs.nlargest(10, 'bot_score')[['Name', 'Subscribers', 'Submission Type', 'bot_score']]\n",
    "print(\"Top 10 subreddits potentially vulnerable to bot influence:\")\n",
    "print(top_vulnerable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "# import time\n",
    "\n",
    "# Filter for subreddits that allow only self or link submissions\n",
    "eligible_subreddits = [\n",
    "    subreddit\n",
    "    for subreddit in subreddits[:100]\n",
    "    if subreddit.submission_type in (\"self\", \"link\")\n",
    "]\n",
    "\n",
    "# Select 10 random subreddits from the filtered list\n",
    "if len(eligible_subreddits) >= 10:\n",
    "    random_subreddits = random.sample(eligible_subreddits, 10)\n",
    "else:\n",
    "    random_subreddits = eligible_subreddits\n",
    "    print(\"Warning: Less than 10 subreddits found matching the criteria.\")\n",
    "\n",
    "# --- POST FETCHING ---\n",
    "posts_data = []\n",
    "for subreddit in random_subreddits:\n",
    "    print(f\"Fetching posts from r/{subreddit.display_name}...\")\n",
    "    try:\n",
    "        # Fetch posts from the 'hot' category\n",
    "        subreddit_posts = []  # Keep track of posts for this subreddit\n",
    "        for post in subreddit.hot(limit=None):  # Use limit=None for maximum allowed\n",
    "            subreddit_posts.append(post)  # Add post to the list\n",
    "\n",
    "        for post in subreddit_posts:\n",
    "            posts_data.append(\n",
    "                {\n",
    "                    \"subreddit\": subreddit.display_name,\n",
    "                    \"title\": post.title,\n",
    "                    \"author\": post.author.name if post.author else \"[deleted]\",\n",
    "                    \"score\": post.score,\n",
    "                    \"upvote_ratio\": post.upvote_ratio,\n",
    "                    \"num_comments\": post.num_comments,\n",
    "                    \"created_utc\": post.created_utc,\n",
    "                    \"selftext\": post.selftext,  # Content of self-posts\n",
    "                    \"url\": post.url,  # URL for link posts\n",
    "                    \"permalink\": post.permalink,  # Permalink to the post\n",
    "                }\n",
    "            )\n",
    "    except Exception as e:\n",
    "        print(f\"   Error fetching posts from r/{subreddit.display_name}: {e}\")\n",
    "        print(f\"   Skipping to the next subreddit...\")\n",
    "        continue\n",
    "\n",
    "    print(\n",
    "        f\"   Fetched {len(subreddit_posts)} posts from r/{subreddit.display_name}.\"\n",
    "    )\n",
    "    # time.sleep(2)  # Add a delay to respect API rate limits\n",
    "\n",
    "# --- CREATE DATAFRAME ---\n",
    "posts_df = pd.DataFrame(posts_data)\n",
    "\n",
    "# --- DISPLAY OR SAVE DATAFRAME ---\n",
    "print(posts_df)\n",
    "# Or, save to CSV:\n",
    "# posts_df.to_csv(\"reddit_posts.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
